{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The Pytest Cookbook - recipes with videos and repos","text":""},{"location":"#motivation","title":"Motivation","text":"<p>I really enjoy coming a across a resource that helps me understand a subject and that has a repo of the code that works 'out of the box' and additionally a video explainer rather than just an article.</p> <p>I have created or collected such resources and combined them into a 'book', citing references where appropriate.</p>"},{"location":"#purpose_of_this_book","title":"Purpose of this book","text":"<ol> <li> <p>To provide a number of ready built and congfigurable FULL STACK PYTHON TEST FRAMEWORK, (PFS), comprising of over 200 highly commented test templates for developers to adapt to their own needs along with resource links that have helped me greatly, as well as integration of these into the frameworks.</p> </li> <li> <p>To provide a curated source of articles and videos that surround PyTest, for example Docker, that enable 'out of the box' ease of use. Some are created by me, others reference with acknowledgments other sources.</p> </li> </ol>"},{"location":"#pytest_full_stack_pfs","title":"PyTest Full Stack, (PFS)","text":"<p>The PyTest Full Stack suite has an installation that will just require a 1-2-3 of:</p> <ol> <li><code>pip install -r requirements.txt</code>.</li> <li><code>playwright install</code> to load Playwright browsers.</li> <li><code>python -m pytest -v</code> to run over 200 tests.</li> </ol> <p>PFS uses a number of PyTest hooks for utilities and features.</p> <p>One of these is customising the terminal report and one can configure the output in a number of ways, explained in articles and videos.</p> <p>Here is a sample output:</p>"},{"location":"#custom_header_sections","title":"Custom header sections","text":""},{"location":"#customised_words_colours_and_icons","title":"Customised words, colours and icons","text":""},{"location":"#custom_footer_sections","title":"Custom footer sections","text":"<p>The frameworks have logging and other utilities installed to provide a complete framework.</p> <p>Resources included are:</p> <ol> <li>Links to helpful articles, videos and documentation. </li> <li>Converted and transcribed code of great YT videos where there is no code repo.</li> </ol>"},{"location":"#test_frameworks","title":"Test frameworks","text":"<p>See the README.md in root of each test framework for detailed and up to date set up instructions.</p> <p>There are two main test frameworks:</p> <ul> <li>PyTest Full Stack - a full stack testing framework from SQL Schemas to E2E testing with Playwright</li> <li>PyTest Django Full Stack- is its own unique testing framework built from a range of sources. (Under construction and will be a PyTest-Full-Stack test suite for Django).</li> </ul> <p>I strive to acknowledge sources I have used to learn PyTest and any adaptations of code samples used therein.</p> <p>As a curated list of resources, I have integrity over linking to the work of others and due credits are given.</p> <p>Often I am a wrapper around someone else's effort and I try to add a different presentation whre possible, as we often find our understanding with a different presentation of the subject. Hence having may teachers enables us all as eternal students to get our heads around sometimes very complex subjects.</p> <p></p>"},{"location":"learn/","title":"Learning PyTest - Suggested path","text":"<p>I have made some videos to assist in using this PyTest Cookbook and how to customise the hooks and plugins used to create custom terminal reports and custom CSV files.</p> <p>These videos are available here.</p>"},{"location":"learn/#1_coffeebeforearch","title":"1. CoffeeBeforeArch","text":"<p>Located in <code>02_py_coffee</code> in PFS, this is a great video series on PyTest. I have included the tests form his repo as part of the template tests. Links in repo.</p> <p>CoffeeBeforeArch</p>"},{"location":"learn/#2_indian_pythonista","title":"2. Indian Pythonista","text":"<p>Located in <code>03_indian_pythonista</code> in PFS, this is another great video series that has source code included.</p> <p>Indian Pythonista</p>"},{"location":"learn/#3_pytest_with_eric","title":"3. PyTest with Eric","text":"<p>This is perhaps one of the best resources for PyTest, PyTestWithEric, and I am creating videos of them and incorporating the GitHub code to provide a second content delivery medium, explaining salient points.</p> <p>This is both for my own technical development and a way of creating a greater audience for this body of work.</p> <p>I have started recording videos of me go through the article and adding them to PyTest Full Stack in <code>60_pwe</code>.</p> <p>Playlist PyTest With Eric</p> <p>Articles videod:</p> <ul> <li>01 pytest-html</li> <li>02 suppress warnings</li> <li>03 read yaml files with argparse and typer and test</li> <li>04 transactions with SQL Model</li> <li>05 setting up allure reporting</li> <li>06 automated testing with GitHub actions</li> <li>07 wiring of the big Mortgage Calculator FastAPI test suite</li> </ul>"},{"location":"learn/#4_brian_okken","title":"4. Brian Okken","text":"<p>Python Testing with pytest, Second Edition Simple, Rapid, Effective, and Scalable by Brian Okken</p> <p>The definitive book!</p> <p></p> <p>https://pragprog.com/titles/bopytest2/python-testing-with-pytest-second-edition/</p>"},{"location":"learn/#5_hooks_and_plugins","title":"5. Hooks and Plugins","text":"<p>For an advanced look at these topics, I have my course hosted on Udemy:</p> <p>The course is available Udemy Hooks and Plugins course and Udemy has a sale ever two weeks and the cost would be $20 USD approx.</p> <p></p> <p>The repo contains heavily commented source files creating a sort of 'ebook' and is freely available https://github.com/Python-Test-Engineer/Udemy-PyTest. The video course adds visual explanations and commentary.</p> <p></p>"},{"location":"asides/asides/","title":"Asides","text":""},{"location":"asides/asides/#what_are_asides","title":"What are asides?","text":"<p>Asides are articles on useful aspects of PyTest Full Stack but are not part of a PyTest Full Stack Run.</p> <p>For example, we have a folder <code>docker</code> that is integrated into PFS, but we also have an isolated set of docker tests that would need to be run in a separate and isolated environment with elements of PFS added in. </p> <p>Essentially the converse of what we are doing in PFS.</p> <p>An example is tests/_isolated_suites which has a docker-postgres-fixtup suite.</p>"},{"location":"asides/asides/#pluggy","title":"Pluggy","text":"<p>Pytest uses Pluggy to have a plugin architecture.</p> <p>Using Pluggy docs, I have created a repo andd video of the examples in the docs as well as extend it to include two plugins rather than just one.</p>"},{"location":"asides/asides/#mocking","title":"Mocking","text":"<p>This covers mock, patch and monkeypatch using Rich and PyBoxed for pretty console output. We look at globals() and sys.modules to see what is happening under the hood as well as create our own mocks to better understand this topic.</p> <p></p>"},{"location":"asides/decorators/","title":"Decorators","text":"<pre><code># a fixture that returns a value\n@pytest.mark.fixture(name=\"init_value\"):\ndef func_value():\n    return some_value\n\n# pytest.mark.fixture is a regular function\n\ndec = pytest.mark.fixture(name=\"init_value\")\ndec(func_value)\n\ngiving us a closure over \"init_value\" which is avaialbe in the decorated function.\n</code></pre>"},{"location":"asides/mocking/","title":"Python Mock, Patch and Monkeypatch","text":""},{"location":"asides/mocking/#about","title":"About","text":"<p>I have created a repo and video series to dive deeper into what mock, patch and monkeypatch do behind the scenes.</p> <p>Using Rich and PyBoxen for pretty console output, we look at globals() and sys.modules to see how we can create our own mocks and patches.</p> <p>We will also look at the source code for <code>mock.py</code> as well as look at a number of template examples that I have collected from various named sources.</p> <p>The hardest part is 'getting' the wiring so it is best to work with the repo and break and fix the tests to really understand that patching involves using `where it is called, not where it is defined'.</p> <p>Regardless, these act as templates and with use the wiring will become clearer.</p>"},{"location":"asides/mocking/#repo","title":"Repo","text":"<p>The repo is here.</p>"},{"location":"asides/mocking/#yt_video_series","title":"YT video series","text":"<p>The series is here.</p> <p>I have endeavoured to make the repo heavily commented so that it can be used as an 'ebook'.</p> <p></p>"},{"location":"asides/pluggy/","title":"Pluggy","text":""},{"location":"asides/pluggy/#about","title":"About","text":"<p>Pluggy as per docs:</p> <ul> <li> <p>pluggy is the crystallized core of plugin management and hook calling for pytest. It enables 1400+ plugins to extend and customize pytest\u2019s default behaviour. Even pytest itself is composed as a set of pluggy plugins which are invoked in sequence according to a well defined set of protocols.</p> </li> <li> <p>It gives users the ability to extend or modify the behaviour of a host program by installing a plugin for that program. The plugin code will run as part of normal program execution, changing or enhancing certain aspects of it.</p> </li> <li> <p>In essence, pluggy enables function hooking so you can build \u201cpluggable\u201d systems.</p> </li> </ul> <p>I have uploaded a video and repo where I have encoded the 'complete example' in the docs and added a second plugin so that the host can be run with two plugins extending its functionality.</p>"},{"location":"asides/pluggy/#repo","title":"Repo","text":"<p>A tested project is available here: GiHub</p>"},{"location":"asides/pluggy/#yt_video","title":"YT Video","text":"<p>There is an explainer video (7mins) to walk through installation and running: YouTube</p> <p></p>"},{"location":"blog/","title":"Blog","text":""},{"location":"craig/contact/","title":"Contact me","text":"<p>Email: iwswordpress@gmail.com</p> <p>LinkedIn: Craig West</p>"},{"location":"craig/courses/","title":"Online courses","text":""},{"location":"craig/courses/#udemycom","title":"Udemy.com","text":"<p>The course Udemy Hooks and Plugins course has just been published and Udemy has a sale ever two weeks and the cost would be $20 USD approx.</p> <p></p> <p>I am currently developing two courses:</p> <ul> <li>Python - mock, patch and monkeypatch.</li> <li>PyTest Django Full Stack - a DB &lt;-&gt; E2E testing of a generic ecommerce store.</li> </ul> <p>The aim is to make them generic, ready to go templates, that also dive deeper into aspects of Python.</p> <p>I am of the opinion that as developers we do not need to reinvent the wheel - it has (almost) all been done before - and that we should be free to use our creativity to build great proucts.</p> <p>The type of course I would want...</p> <p></p>"},{"location":"craig/cv/","title":"CV","text":""},{"location":"craig/cv/#github_cv","title":"GitHub CV","text":"<p>I use GitHub to host a copy of my CV.</p> <p>Github CV</p>"},{"location":"craig/cv/#python_backend_and_test_automation_engineer","title":"Python Backend and Test Automation Engineer","text":"<ul> <li>Degree in Chemistry, Oxford University.</li> <li>Former A+ PC Technician, Microsoft Certified Systems Engineer and Microsoft Certified SQL Server DBA.</li> <li>Former Business Information Architect.</li> <li>Qualified Accountant Technician and business owner.</li> <li>Experience with REST APIs, GraphQL, React, Vue, Web Components, Node, Docker</li> <li>Talks and workshops given at WordCamps, MeetUps and NDC.</li> </ul>"},{"location":"craig/cv/#talks_and_workshops","title":"Talks and Workshops","text":"<p>A list of talks and workshops I have given: </p> <ul> <li> <p>TALK: Offline and instant websites, aka Progressive Web Apps - AsyncJS, Brighton, September 2021.</p> </li> <li> <p>LIGHTNING TALK: WordPress as a Micro Service to any framework - WordFest, July 2021.</p> </li> <li> <p>TALK: WP REST API and Web Components =&gt; 100% Internet - WordCamp Santa Clarita, July 2021.</p> </li> <li> <p>TALK: Web Components in WP, Gutenberg and as HTML plugins. - WordCamp North East Ohio May 2021.</p> </li> <li> <p>TALK: Leveraging the power or the WordPress REST API - WP Leeds April 2021</p> </li> <li> <p>WORKSHOP: WP REST API and you -&gt; Best Friends Forever workshop (90 mins) - WordCamp Greece April 2021 </p> </li> <li> <p>TALK: Web Components as Micro Apps - NDC London, Jan 2021</p> </li> <li> <p>TALK: Unifying frameworks with Web Components - Brighton AsyncJS, Nov 2020</p> </li> <li> <p>WORKSHOP: Progressive Web Apps Workshop (2hrs) - NDC Oslo June 2020 and a paid training workshop with NDC</p> </li> <li> <p>WORKSHOP: Web Components Workshop (2hrs) - NDC Oslo June 2020 and a paid training workshope with NDC</p> </li> <li> <p>WORKSHOP: Progressive Web Apps Workshop (2hrs) - Brighton WordUp June 2020</p> </li> <li> <p>WORKSHOP: WordPress REST API with AJAX Forms and Pages - WordCamp Denver, June 2020.</p> </li> <li> <p>WORKSHOP: WordPress REST API with AJAX Forms and Pages - WordCamp Kent, Ohio May 2020.</p> </li> <li> <p>TALK: What is the WP REST API and how can I use it to make forms and pages that don\u2019t need to do be reloaded? - WordUp Brighton May 2020.</p> </li> <li> <p>WORKSHOP: WordPress REST API and AJAX Forms - WordCamp Geneva March 2020 EVENT CANCELLED due to virus concerns </p> </li> <li> <p>TALK - WP-HTML: The marriage of WP and JS Frameworks for expansion, ubiquity and profit - WordCamp Vienna February 2020.</p> </li> <li> <p>WORKSHOP: WordPress REST API - WordCamp Vienna February 2020.</p> </li> <li> <p>TALK: Progressive Web Apps - Brighton WordUp November 2019.</p> </li> <li> <p>TALK: Decoupled WordPress (code along style) - WordCamp Dublin October 2019.</p> </li> <li> <p>TALK: JWT and Authentication - WPHooked London September 2019</p> </li> <li> <p>TALK: Decoupled WordPress and WP Components - WordCamp Brighton August 2019.</p> </li> </ul>"},{"location":"craig/cv/#published_udemy_courses","title":"Published Udemy Courses","text":"<p>Udemy is a great learning platform and having sales at least once a month, courses can be purchased for ~ \u00a315/$15 USD.</p> <p>These have now been retired.</p> <ul> <li>WordPress REST API and AJAX Forms/Pages - DEMO https://www.youtube.com/watch?v=eubhbcGH_Ws&amp;t=6s (paid)</li> <li>Progressive Web Apps - DEMO https://www.youtube.com/watch?v=k_lHvNL0gkw (paid)</li> <li>WP-HTML: decoupling WordPress to any HTML platform using Web Components and the WP REST API. This also enables HTML plugins for non-WP Sites - https://www.udemy.com/course/powerful-html-pages-using-wordpress-component-architecture/ (free)</li> <li>Stylish Dynamic Web Forms with jQuery validation - https://www.udemy.com/course/ready-to-use-form-validation-templates-with-jquery/ (free)</li> </ul>"},{"location":"craig/cv/#youtube_courses_-_developer_to_developer_courses","title":"YouTube Courses - Developer to Developer courses","text":"<p>These are video courses that cover work through official documents to help other developers, learn in public and show prosepective employers not just what I know but how I learn and how I communicate technical matters to others.</p> <p>There are also some specific videos explaining solutions to set ups other developers may encounter.</p> <ul> <li> <p>HIGHLY-FUNCTIONAL-WEBCOMPONENTS: A video course based on the workshop I gave at NDC Oslo June 2020 - https://www.youtube.com/watch?v=QC-JTqQTv2k&amp;list=PLsszRSbzjyvkQwzrJobroRl7z7MfSlePa </p> </li> <li> <p>WP Plugin Boilerplate:  I havea video series to explain WP Plugin Boilerplate using a scaffolded out project that demonstrates the use of MySQL, wp_nonce, REST API, forms and how to redirect pages to plugin templates to make the plugin theme independent. https://www.youtube.com/watch?v=lJ9ktD4JOfs&amp;list=PLsszRSbzjyvn-RQr4dEjrgnTne2HcJKee</p> </li> </ul>"},{"location":"craig/cv/#volunteering","title":"Volunteering","text":"<p>I volunteer at Codebar.io in Brighton as well as some Community Kitchens.</p>"},{"location":"craig/cv/#outside_interests","title":"Outside interests","text":"<p>These include Community Kitchens, gym, occasional partner dancing and DIY.</p> <p></p>"},{"location":"craig/services/","title":"Services provided","text":""},{"location":"craig/services/#backend_pythonista_and_test_automation_engineer","title":"Backend Pythonista and Test Automation Engineer","text":""},{"location":"craig/services/#skillset","title":"Skillset","text":"<p>Primarily:</p> <ul> <li>Python</li> <li>PyTest</li> <li>Playwright</li> <li>Django</li> </ul> <p>Tools:</p> <p>I strive to dive deeper into these tools and see them as programming languages in their own right. DevOps seems to be an essential part of my work:</p> <ul> <li>Shell Scripting</li> <li>Git/GitHub Actions</li> <li>Docker</li> </ul>"},{"location":"craig/services/#engagement_style","title":"Engagement Style","text":"<p>I offer on-demand, freelance services starting from 1/2 day blocks.</p> <p>As and when you need it...</p> <p>Tech is a way of life for me not just a job and I strive to have enthusiasm and passion for the projects I work on. Professional fulfilment is paramount.</p>"},{"location":"craig/services/#eligibility","title":"Eligibility","text":"<ul> <li>UK National</li> <li>Fluent English</li> </ul>"},{"location":"craig/services/#on-sitehybrid","title":"On-site/Hybrid","text":"<p>I am based in Brighton and enjoy (local) on-site work as well as working from my home office.</p>"},{"location":"craig/services/#volunteer_coach","title":"Volunteer Coach","text":"<p>I am a volunteer coach with Codebar Brighton.</p>"},{"location":"craig/services/#youtube","title":"YouTube","text":"<p>I produce a large amount of content that is associated with a repo that enables 'out of the box' ease of use.</p> <p>If I find good videos without a repo, I often create a repo and my own video with reference to the source video. I have no commercial interest in this matter.</p> <p>My YouTube Channel</p>"},{"location":"craig/services/#outside_of_tech","title":"Outside of tech...","text":"<p>I enjoy working in community kitchens and love laughter, creating, doing and trying to work out why things are funny.</p> <p></p>"},{"location":"django_testing/","title":"PyTest Django Full Stack","text":"<p>I have decided to produce a book or technical manual on Full Stack Django Testing, with a companion video course.</p> <p>This is a work in progress.</p> <p>This can be found here:</p> <p>https://django-fullstack-testing.netlify.app/</p>"},{"location":"docker/docker_advanced/","title":"Advanced Docker","text":"<p>This is a selection of less shown aspects of Docker, not necessarily advanced Docker but more uncommon.</p>"},{"location":"docker/docker_advanced/#version_deprecated","title":"'version' deprecated","text":"<p>A <code>docker-compose.yaml</code> file no longer needs the <code>VERSION</code> at top.</p> <p>One can also use a different named file with the <code>-f</code> flag: <code>docker compose -f another_file.yaml up</code> and we can avoid the use of <code>docker-compose</code> in favor of <code>docker compose</code>.</p> <p>We can use <code>compose.yml</code> in <code>place of docker-compose.yml</code></p>"},{"location":"docker/docker_advanced/#depends_on","title":"Depends On","text":"<p>https://www.warp.dev/terminus/docker-compose-depends-on</p> <p>Whilst <code>depends on</code> defines a dependency, to check that the service is running we can use:</p> <pre><code>services:\n  api:\n    build: .\n    depends_on:\n      database:\n        condition: service_started\n  database:\n    image: postgres\n</code></pre> <p><pre><code>services:\n  api:\n    build: .\n    depends_on:\n      database:\n        condition: service_healthy\n  database:\n    image: postgres\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready\"]\n</code></pre> <pre><code>services:\n  api:\n    build: .\n    depends_on:\n      database:\n        condition: service_healthy\n      migration:\n        condition: service_completed_successfully\n  database:\n    image: postgres\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready\"]\n</code></pre></p> <p>A good short video on this is https://www.youtube.com/watch?v=BTXfR76WmCw.</p>"},{"location":"docker/docker_advanced/#develop_and_watch","title":"Develop and watch","text":"<p>There is an alternative way for reloading without rebuilding that does not need bind mounts:</p> <p></p> <p>DockerCon2023 Video on Compose Develop</p> <p>Docs: https://docs.docker.com/compose/file-watch/</p> <pre><code>services:\n  web:\n    build: .\n    command: npm start\n    develop:\n      watch:\n        - action: sync\n          path: ./web\n          target: /src/web\n          ignore:\n            - node_modules/\n        - action: rebuild\n          path: package.json\n</code></pre> <p>We can set either <code>rebuild</code> if the image needs rebuilding when we change requirements.txt for example and we can use <code>sync</code> when our code changes.</p> <p><code>sync+restart</code> is ideal when config file changes, and you don't need to rebuild the image but just restart the main process of the service containers. It will work well when you update a database configuration or your nginx.conf file for example</p>"},{"location":"docker/docker_advanced/#labels","title":"Labels","text":"<p>Labels are useful to add metadata:</p> <pre><code>FROM ubuntu:latest\nLABEL \"website.name\"=\"example.com\"\nLABEL maintainer=\"me\"\nLABEL website=\"geeksforgeeks\"\nLABEL desc=\"This is docker tutorial\"\n</code></pre>"},{"location":"docker/docker_advanced/#overide_include_and_merge","title":"Overide, include and merge","text":"<p>Files can be overriden, merge or have include files.</p> <p>https://docs.docker.com/compose/multiple-compose-files/extends/#extending-services-from-another-file]</p> <p>For example:</p> <p><code>docker compose -f compose.yml -f compose.admin.yml run backup_db</code> The compose.yml file might specify a webapp service.</p> <p><pre><code>webapp:\n  image: examples/web\n  ports:\n    - \"8000:8000\"\n  volumes:\n    - \"/data\"\n  environment:\n    - DEBUG=1\n</code></pre> The compose.admin.yml may also specify this same service:</p> <p><pre><code>webapp:\n  ports:\n    - \"9000:8000\"\n  environment:\n    - ANOTHER_VARIABLE=value\n</code></pre> Any matching fields override the previous file. New values, add to the webapp service configuration:</p> <pre><code>webapp:\n  image: examples/web\n  ports:\n    - \"9000:8000\"\n  volumes:\n    - \"/data\"\n  environment:\n    - DEBUG=1\n    - ANOTHER_VARIABLE=value\n</code></pre> <p>This is efectively, like updating a dictonary where we just pass in fields to be add/updated and copy in the remaining fields.</p> <p>It is also worth noting that if we have two docker composes files such as <code>docker-compose.yml</code> and <code>docker-compose-override.yml</code> then running <code>docker compose up</code> will run <code>docker-compose.yml</code> and then automatically run <code>docker-compose-override.yml</code>.</p> <p>https://docs.docker.com/compose/multiple-compose-files/merge/ or </p> <pre><code>Merge Compose files\nDocker Compose lets you merge and override a set of Compose files together to create a composite Compose file.\n\nBy default, Compose reads two files, a compose.yml and an optional compose.override.yml file. By convention, the compose.yml contains your base configuration. The override file can contain configuration overrides for existing services or entirely new services.\n\nIf a service is defined in both files, Compose merges the configurations using the rules described below and in the Compose Specification.\n</code></pre>"},{"location":"docker/docker_advanced/#multi_stage_builds","title":"Multi stage builds","text":"<p>Many times, one part of the build creates artificacts that are used in the main image.</p> <p>By using multi stage builds, the artifiact and not the images needed to create them are used in the main image build.</p> <p>For example, we might build an artifact in Cpython to use in our image build. We don't want the Cpython compiler image included in the final image, just the code.</p> <p>FastAPI Docker To Go has an example of a multi stage build where we create a simple artifact of <code>test.txt</code> with the current date and time and copy this into the final image.</p>"},{"location":"docker/docker_advanced/#securing_secrets","title":"Securing secrets","text":"<p>The video below is a very good explainer of how 'secrets' can be exposed and how to prevent this.</p> <p>YouTube</p>"},{"location":"docker/docker_advanced/#under_the_hood","title":"Under the hood","text":"<p>Under the hood, Docker uses Linux features such as Cgroups, Namespaces and Overlay File System, to create the illusion that a Docker container is its only world.</p> <p>There are two very good YT talks on this:</p> <ul> <li>https://www.youtube.com/watch?v=_TsSmSu57Zo</li> <li>https://www.youtube.com/watch?v=JOsWB50LmwQ</li> <li>For a course to learn about Linux Containerisation to see what Docker does under the hood: Docker under the hood</li> </ul> <p></p>"},{"location":"docker/docker_flask_pdb/","title":"Multiple container testing","text":"<p>This is inspired by the excellent courst 'Python in Containers' on Udemy.</p> <p>We build a flask image and this is used as one layer for another image for testing.</p> <p>An explainer video is here: YouTube Video.</p> <p>The repo is here.</p> <p>It introduces the use of Docker's ARG, where we can specify at build time another image. </p> <p>Generally, nothing can come before FROM as this creates a new shell as it were.</p> <p>However, we can use ARG to be able to pass in arguments in the CLI build:</p>"},{"location":"docker/docker_flask_pdb/#base_image","title":"Base Image","text":"<pre><code>ARG BaseImage\nFROM $BaseImage\n</code></pre>"},{"location":"docker/docker_flask_pdb/#use_--build-arg","title":"use --build-arg","text":"<pre><code>docker build -t factors_flask_tester -f Dockerfile.tester --build-arg BaseImage=factors_flask_pdb .\n</code></pre> <p>Tests are carried out on the <code>factors_flask_tester</code> image.</p> <p>Note, we can use the -f flag to select a Dockerfile. This can be a convenience when we have several Dockerfiles we want to use but don't want to have to overwrite the root Dockerfile.</p> <p></p>"},{"location":"docker/docker_index/","title":"Docker","text":"<p>Docker seems to be an essential part of testing work.</p> <p>As a result, I have a dedicated section for Docker apps.</p> <p>A useful script builder provided by Docker is: Article and Video</p> <p>Docker Docs</p> <p></p>"},{"location":"docker/docker_postgres_setup/","title":"Docker Postgress PgAdmin Adminer","text":"<p>It has both PgAdmin and Adminer as Postgress clients.</p> <p>There are range of SQL Crud files included so that you have Python-Docker-Postgres working.</p> <p>I had some issues with this type of set up but came up with my own docker-compose file.</p> <p>YouTube Video</p> <p>The repo is here: GitHub</p> <p>There are a number of ways to set up a volume - named or bind mount.</p> <p>The latter use a folder within your project, whereas a named volume is managed by Docker and persists after the container is stopped.</p> <p>The repo has docker-compose.yaml files for both types.</p> <p>Bind mount volume:</p> <p><pre><code>volumes:\n   - ./db-data/:/var/lib/postgresql/data/\n</code></pre> Named volume: <pre><code>volumes:\n   - data:/var/lib/postgresql/data/\n</code></pre></p> <p>Additonally, this video looks at setting up scripts automatically: https://www.youtube.com/watch?v=EtWTa27G4wE.</p> <p></p>"},{"location":"docker/docker_to_go/","title":"Docker To Go","text":"<p>I have a range of Docker multi-container apps and the repo is here.</p> <p>The following have been added and tested as of 28JUN2024</p>"},{"location":"docker/docker_to_go/#django_sqlitepostgres","title":"Django Sqlite/Postgres","text":"<p>This uses the PythonCRUD-Postgres-PgAdmin-Adminer in the Docker To Go repo to set up a Postgres container.</p> <p>There are a number of settings.py files:</p> <ul> <li><code>settings.py</code> with default SQLite</li> <li><code>settings_sqlite.py</code> with default SQLite</li> <li><code>settings_postgres.py</code>with Posgres connection</li> </ul> <p>They can be merged into one with SQLite or Postgres commented out or copy appropriate settings file to <code>settings.py</code>.</p>"},{"location":"docker/docker_to_go/#fastapi_with_reload","title":"FastAPI with reload","text":"<p>FastAPI with hot reload on code change YouTube.</p>"},{"location":"docker/docker_to_go/#fastapi_multi-stage_build","title":"FastAPI Multi-Stage build","text":"<p>We can use FROM many times with the last FROM being the final image.</p> <p>To do this we need to use the multi-stage implementation as defined in the docs: https://docs.docker.com/build/building/multi-stage/.</p> <p>In this example we use the DockerfileMultiStage file as the Docerfile and carry out the build in the same way. We create an artifact of <code>test.txt</code> with the current date and time and copy this into the final image. </p> <p>The use case for this is to create cython files for time-consuming modules. We want the binaries but not all the cpython files necessary to build the final binary. </p> <p>Using multi-stage builds, we can Dockerise the artifact and copy this into the final image, reducing the final size of the image and the time needed to rebuild it when the binary build does not change but the final image does, e.g. when we change our code and we have reload enabled.</p> <p>YouTube Video</p>"},{"location":"docker/docker_to_go/#pythoncrud-postgres-pgadmin-adminer","title":"PythonCRUD-Postgres-PgAdmin-Adminer","text":"<p>This has the PythonCRUD-Postgres-PgAdmin-Adminer set up YouTube.</p>"},{"location":"docker/docker_to_go/#flask-redis","title":"Flask-Redis","text":"<p>Details to follow...</p>"},{"location":"docker/docker_to_go/#nginx-flask-mysql","title":"Nginx-Flask-MySQL","text":"<p>Details to follow...</p> <p></p>"},{"location":"docker/pytest_docker_plugin/","title":"PyTest and Docker","text":"<p>Docker seems to be an essential part of testing work.</p> <p>As a result, I have a section on Docker, with a sub section of Docker To Go, a range of ready made Docker set ups: Docker.</p>"},{"location":"docker/pytest_docker_plugin/#docker_and_pytest_full_stack","title":"Docker and PyTest Full Stack","text":"<p>PyTest-Full-Stack has one example using <code>pytest-docker</code>.</p> <p>Ensure docker desktop or equivalent is running! \ud83d\ude2c </p> <p>Located in tests/docker. My usual folder naming of 70_docker is unacceptable so I just use docker.</p> <p>There is a YT video of this: pytest-docker.</p>"},{"location":"docker/pytest_docker_plugin/#useful_courses","title":"Useful courses","text":"<p>I have done many trainings on Docker and I would say the best training is on my favourite platform Udemy: Docker Bootcamp: Conquer Docker with Real-World Projects</p> <p>Sales every two weeks or so will mean you can get if for $20 USD or so. </p> <p>What I really like about this course is it does not really go into theory but just builds a great number of microservices and connects them. Repetition makes it become part of the muscle and is probably what is needed for a Test Engineer.</p> <p>There are other courses that go deeper and one that I find really good is: Python in Containers</p> <p></p>"},{"location":"pytest/","title":"PyTest Full Stack","text":""},{"location":"pytest/#full_stack","title":"Full Stack","text":"<p>This framework has tests covering:</p> <ul> <li>SQL Schemas for foreign keys, number of tables, check constraints etc...</li> <li>Unit tests</li> <li>Integrations tests</li> <li>Mock, patch and monkeypatch templates</li> <li>Behavior Driven Testing templates</li> <li>API testing</li> <li>End to End testing with Playwright</li> </ul>"},{"location":"pytest/#youtube_videos","title":"YouTube videos","text":"<p>Videos are available here: YouTube </p>"},{"location":"pytest/#repo","title":"Repo","text":"<p>The PyTest Full Stack repo is available here: PyTest Full Stack</p>"},{"location":"pytest/#installation","title":"Installation","text":"<ul> <li><code>git clone https://github.com/Python-Test-Engineer/PyTest-Full-Stack</code></li> <li>Create virtual enviroment <code>python -m venv venv</code></li> <li>Activate your virtual enviromnent: Windows <code>.\\venv\\Scripts\\activte</code> or Mac <code>source venv\\bin\\activate</code>.</li> <li>install requirements <code>pip install -r requirements.txt</code>.</li> <li>for Playwright browsers run <code>playwright install</code>.</li> <li>run all tests <code>python -m pytest -vs</code>.</li> <li>There are around 200 templated tests.</li> <li>The video series goes into features and utililities: YouTube</li> </ul>"},{"location":"pytest/pytest_allure/","title":"Allure Reporting - Windows","text":"<p>This has not been installed in PyTest-Full-Stack but a fine article, as ever, is https://pytest-with-eric.com/reporting/pytest-allure-report/.</p> <p>You will need Allure to run this repo and Java needs to be installed.</p> <p>If you are on Windows, like me, we can set up Java/Allure as follows:</p> <p>I used the following video - Useful JDK Video and adapted it to my own video - Install Java.</p> <p>To install Allure: </p> <p>Allure Install Video</p> <ul> <li>For Allure, download the zip of the version you want.</li> <li>Unzip and place in a location of your choice.</li> <li>Add the path in environment variables. Mine was C:\\allure\\bin</li> </ul>"},{"location":"pytest/pytest_cheat2/","title":"Pytest Commands","text":"<p>Source: Very Academy</p> <p>This guide outlines various commands to run tests using pytest.</p> <ul> <li>Run pytest: <pre><code>pytest\n</code></pre></li> <li> <p>Run pytest specify markers: <pre><code>pytest -m &lt;marker&gt;\npytest -m \"&lt;marker&gt; and &lt;marker&gt;\"\n</code></pre></p> </li> <li> <p>Run all tests in a directory: <pre><code>pytest path/to/directory\n</code></pre></p> </li> <li> <p>Run tests in a specific file: <pre><code>pytest path/to/test_file.py\n</code></pre></p> </li> <li> <p>Run a specific test function: <pre><code>pytest path/to/test_file.py::test_function\n</code></pre></p> </li> <li> <p>Run tests that match a specific substring: <pre><code>pytest -k \"substring\"\n</code></pre></p> </li> <li> <p>Run tests based on markers: <pre><code>pytest -m \"marker_name\"\npytest -m \"model and model_structure\"\npytest -m \"model or model_structure\"\n</code></pre></p> </li> <li> <p>Run tests and generate code coverage report: <pre><code>pytest --cov=path/to/package\n</code></pre></p> </li> <li> <p>Run tests and display print statements: <pre><code>pytest -s\n</code></pre></p> </li> <li> <p>Run tests and stop at the first failure: <pre><code>pytest --exitfirst\n</code></pre></p> </li> <li> <p>Run tests in parallel: <pre><code>pytest -n num_workers\n</code></pre></p> </li> <li> <p>Run tests with verbose output: <pre><code>pytest -v\n</code></pre></p> </li> <li> <p>Run tests and ignore warnings: <pre><code>pytest -p no:warnings\n</code></pre></p> </li> <li> <p>Run tests and rerun failed tests: <pre><code>pytest --reruns num_reruns\n</code></pre></p> </li> <li> <p>Run tests and mark them as slow: <pre><code>pytest --slow\n</code></pre></p> </li> <li> <p>Run tests and mark them as xfail (expected to fail): <pre><code>pytest --xfail\n</code></pre></p> </li> </ul>"},{"location":"pytest/pytest_cheat_sheet/","title":"PyTest Cheatsheet","text":""},{"location":"pytest/pytest_cheat_sheet/#source","title":"Source","text":"<p>https://gist.github./comkwmiebach/3fd49612ef7a52b5ce3a</p> <p>I have made some amendments to original version</p>"},{"location":"pytest/pytest_cheat_sheet/#usage","title":"Usage","text":"<p>(Create a symlink pytest for py.test)</p> <pre><code>pytest [options] [file_or_dir] [file_or_dir] ...\n</code></pre> <p>Help:</p> <pre><code>pytest --help|zless\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#warnings","title":"Warnings","text":"<p>There is a video I made in 'PyTest with Eric' https://www.youtube.com/watch?v=UPnXsSU9mHE which links to his article as well.</p> <p>The docs also have a comprehensive set of possibilities https://docs.pytest.org/en/7.1.x/how-to/capture-warnings.html#how-to-capture-warnings.</p>"},{"location":"pytest/pytest_cheat_sheet/#some_options","title":"Some options","text":"<pre><code> -s                    Show Output, do not caputure\n -x                    Stop after first failure\n -k \"expression\"       Only run tests that match expession (and fixtures)\n -rs                   Show extra summary info for SKIPPED\n -r chars              Show extra test summary info as specified by chars:\n                       (f)ailed, (E)error, (s)skipped, (x)failed, (X)passed\n                       (w)pytest-warnings (p)passed, (P)passed with output,\n                       (a)all except pP.\n\n -v                    Verbose\n -q, --quiet           Less verbose\n\n -l, --showlocals      Show local variables in tracebacks\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#shorter_tracebacks_python_tracebacks","title":"Shorter tracebacks, python tracebacks","text":"<pre><code>pytest --tb=short\npytest --tb=line # even shorter\n</code></pre> <p>Use the Python standard traceback formatting:</p> <pre><code>pytest --tb=native\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#output_capturing","title":"Output capturing","text":"<pre><code>pytest -s # disable all capturing\n</code></pre> <p>https://pytest.org/latest/capture.html#capturing-of-the-stdout-stderr-output</p>"},{"location":"pytest/pytest_cheat_sheet/#print_a_message_after_the_test","title":"Print a message after the test","text":"<p>The text is printed always, even in silent mode. See https://stackoverflow.com/a/38806934/362951</p> <pre><code>def report():\n  print(\"\"\"This is printed AFTER the test\"\"\")\nimport atexit\natexit.register(report)\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#collect_information_test_suite_dry_run","title":"Collect information test suite / dry run","text":"<pre><code>py.test test_sample.py --collect-only\n</code></pre> <p>(will not display fixture code but fixture code will be run always)</p>"},{"location":"pytest/pytest_cheat_sheet/#output_verbose_messages","title":"Output verbose messages","text":"<pre><code>py.test test_sample.py -v\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#run_a_single_test_specify_filepyclassname_like_so","title":"Run a single test: specify file.py::ClassName, like so","text":"<pre><code>py.test -q -s test_file.py::ClassName\n</code></pre> <p>(fixture code will also run)</p>"},{"location":"pytest/pytest_cheat_sheet/#ignore_exclude_certain_files_or_directories","title":"Ignore / exclude certain files or directories","text":"<pre><code>--ignore=lib/foo/bar.py --ignore=lib/hello/\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#call_pytest_through_python","title":"Call pytest through python","text":"<pre><code>python -m pytest -q test_sample.py\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#call_pytest_from_python","title":"Call pytest from python","text":"<p>Calling pytest programaticaly / from code:</p> <pre><code>import pytest\n# put all arguments into a string. example:\npytest.main(\"g/src/app/art/__init_unit.py\")    \n# another example:\npytest.main(\"-x mytestdir\")\n# or pass in a list of arguments:\npytest.main(['-x', 'mytestdir'])\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#show_available_markers","title":"Show available markers","text":"<pre><code>py.test --markers\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#create_a_reusable_marker","title":"Create a reusable marker","text":"<p>content of pytest.ini:</p> <pre><code>[pytest]\nmarkers =\n   webtest: mark a test as a webtest.\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#only_run_tests_with_names_that_match_the_string_expression","title":"Only run tests with names that match the \"string expression\"","text":"<pre><code>py.test -k \"TestClass and not test_one\"\n</code></pre> <p>(fixture code will also run)</p>"},{"location":"pytest/pytest_cheat_sheet/#only_run_tests_that_match_the_node_id","title":"Only run tests that match the node ID","text":"<pre><code>py.test test_server.py::TestClass::test_method\n</code></pre> <p>(fixture code will also run)</p>"},{"location":"pytest/pytest_cheat_sheet/#stop_after","title":"Stop after","text":"<pre><code>py.test -x  # stop after first failure\n\npy.test --maxfail=2  # stop after two failures\n\npy.test --maxfail=2 -rf  # exit after 2 failures, report fail info.\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#show_local_variables_in_tracebacks","title":"Show local variables in tracebacks","text":"<pre><code>py.test --showlocals \npy.test -l  # (shortcut)\n\npy.test --tb=long  # the default informative traceback formatting\npy.test --tb=native  # the Python standard library formatting\npy.test --tb=short  # a shorter traceback format\npy.test --tb=line  # only one line per failure\npy.test --tb=no  # no tracebak output\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#drop_to_pdb_on_first_failure","title":"Drop to PDB on first failure","text":"<p>(then end test session)</p> <pre><code>py.test -x --pdb\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#list_of_the_slowest_10_test_durations","title":"List of the slowest 10 test durations.","text":"<pre><code>py.test --durations=10\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#send_tests_to_multiple_cpus","title":"Send tests to multiple CPUs","text":"<pre><code>py.test -n 4\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#run_tests_with_decorator_slowest","title":"Run tests with decorator \"slowest\"","text":"<p>Run tests with decorator @pytest.mark.slowest or slowest = pytest.mark.slowest; @slowest</p> <pre><code>py.test -m slowest\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#show_active_plugins","title":"Show active plugins","text":"<p>Find out which plugins are active in your environment</p> <pre><code>py.test --traceconfig\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#instafail","title":"Instafail","text":"<p>if pytest-instafail is installed, show errors and failures instantly instead of waiting until the end of test suite:</p> <pre><code>py.test --instafail\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#expected_exceptions","title":"Expected exceptions","text":"<p>See https://pytest.org/latest/assert.html#assertions-about-expected-exceptions</p> <p>Example:</p> <pre><code>def test_recursion_depth():\n    with pytest.raises(RuntimeError) as excinfo:\n        def f():\n            f()\n        f()\n    assert 'maximum recursion' in str(excinfo.value)\n</code></pre> <p>More usage examples: http://stackoverflow.com/a/15152283/362951</p> <p>Excinfo is a py.code.ExceptionInfo instance: http://pylib.readthedocs.org/en/latest/code.html#py-code-exceptioninfo</p> <p>Its main attributes are type (the exception class), value (the current instance), and traceback (see http://pylib.readthedocs.org/en/latest/code.html#py.code.Traceback) - </p> <p>Also see https://docs.python.org/3.4/library/sys.html#sys.exc_info</p>"},{"location":"pytest/pytest_cheat_sheet/#skip","title":"Skip","text":"<p>Simple use:</p> <p><pre><code>import pytest\npytest.skip(\"Skipping for some reason\")\n</code></pre> Skip a whole module:</p> <pre><code>import pytest\npytest.skip(\"skipping test file\", allow_module_level=True)\n</code></pre> <p>Show skip reasons / info:</p> <pre><code>py.test -rs\n</code></pre> <p>Advanced: https://pytest.org/latest/skipping.html</p>"},{"location":"pytest/pytest_cheat_sheet/#test_using_parametrize","title":"Test using parametrize","text":"<pre><code>import pytest\n\n@pytest.mark.parametrize(\n   ('n', 'expected'), [\n       (1, 2),\n       (2, 3),\n       (3, 4),\n       (4, 5),\n       pytest.mark.xfail((1, 0)),\n       pytest.mark.xfail(reason=\"some bug\")((1, 0)),\n       pytest.mark.skipif('sys.version_info &gt;= (3,0)')((10, 11)),\n   ]\n)\ndef test_increment(n, expected):\n   assert n + 1 == expected\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#configuration","title":"Configuration","text":"<p>See https://docs.pytest.org/en/latest/customize.html</p> <p>Check if there are unexpected pytest.ini, tox.ini or setup.cfg somewhere in the project.</p>"},{"location":"pytest/pytest_cheat_sheet/#known_issues","title":"Known issues","text":""},{"location":"pytest/pytest_cheat_sheet/#assert_error_with_python_35","title":"assert error with python 3.5","text":"<p><code>TypeError: Call constructor takes either 0 or 3 positional arguments</code></p> <p>Workaround: add the parameter <code>--assert=plain</code> to the pytest command</p>"},{"location":"pytest/pytest_cheat_sheet/#pytestini","title":"pytest.ini","text":"<p>Put a section marker at the top:</p> <pre><code>[pytest]\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#line_continuation","title":"Line continuation","text":"<p>indent continued line by 2 spaces:*</p> <pre><code>norecursedirs = \n  .git\n  .idea\n</code></pre>"},{"location":"pytest/pytest_cheat_sheet/#norecursedir","title":"norecursedir","text":"<p>Allows only simple directory names or patterns wihtout <code>/</code>, they are always applied in all subdirectories. For individual directories use: 'addopts --ignore='!</p>"},{"location":"pytest/pytest_cheat_sheet/#addopts","title":"addopts","text":"<p>Example:</p> <p>addopts =    --ignore=./some/dir   --ignore=./some/other/dir   --ignore=./dir1/some.file</p>"},{"location":"pytest/pytest_cheat_sheet/#helper_to_write_dict_to_tmpdatajson","title":"Helper to write dict to /tmp/data.json","text":"<pre><code>def dump1(data, fname=\"/tmp/data.json\"):\n    from json import JSONEncoder\n    class DateTimeAndDecimalEncoder(JSONEncoder):\n        def default(self, obj):\n          import datetime\n          import decimal\n          if isinstance(obj, datetime.datetime):\n            encoded_object = obj.isoformat()\n            # e.g. \"2014-06-22T04:44:14.057000\"\n          elif isinstance(obj, decimal.Decimal):\n            return str(obj)\n          else:\n            encoded_object =JSONEncoder.default(self, obj)\n          return encoded_object\n\n    def dumps_pretty(s):\n        # datetime.datetime(2013, 9, 13, 9, 59, 11) is not JSON serializable\n        import json\n        return\"%s\" % json.dumps(s,\n          sort_keys=True,\n          indent=2,\n          separators=(',', ': '),\n          cls=DateTimeAndDecimalEncoder,\n        )  \n\n    f = open(fname, \"w\")\n    f.write(dumps_pretty(data))\n    f.close()\n</code></pre>"},{"location":"pytest/pytest_docker/","title":"PyTest and Docker","text":"<p>Docker seems to be an essential part of testing work.</p> <p>As a result, I have a section on Docker, with a sub section of Docker To Go, a range of ready made Docker set ups: Docker</p>"},{"location":"pytest/pytest_docker/#docker_and_pytest","title":"Docker and PyTest","text":"<p>There are a number of subjects covered in Toolbox &gt; Docker. The section is here</p>"},{"location":"pytest/pytest_docker/#other_plugins","title":"Other plugins","text":"<p>There are a number of docker plugins for pytest:</p> <ul> <li><code>pytest-docker-compose</code></li> <li><code>pytest-docker-tools</code></li> <li><code>docker-python-unittest-pytest</code> is a more DIY setup.</li> </ul>"},{"location":"pytest/pytest_docker/#docker-postgres-pgadmin-adminer_-_to_go","title":"Docker-Postgres-PGAdmin-Adminer - to go","text":"<p>I have a YT video and repo that I have tested many times myself. It also uses my custom Postgres image which has PGVector extension added for Semantic Search, (AI RAG).</p>"},{"location":"pytest/pytest_docker/#courses","title":"Courses","text":"<p>I have done many trainings on Docker and I would say the best training is on my favourite platform Udemy: Docker Bootcamp: Conquer Docker with Real-World Projects</p> <p>Sales every two weeks or so will mean you can get if for $20 USD or so. </p> <p>What I really like about this course is it does not really go into theory but just builds a great number of microservices and connects them. Repetition makes it become part of the muscle and is probably what is needed for a Test Engineer.</p> <p>There are other courses that go deeper and one that I find really good is: Python in Containers.</p> <p>To learn about Linux Containerisation to see what Docker does under the hood: Docker under the hood</p> <p></p>"},{"location":"pytest/pytest_full_stack_customise/","title":"How to configure your own custom PyTest Full Stack","text":""},{"location":"pytest/pytest_full_stack_customise/#please_see_the_videos_in_the_playlist","title":"Please see the videos in the playlist","text":"<p>YouTube playlist: here</p> <p>This covers:</p> <ul> <li>pytest.ini settings for logging.</li> <li>how to read values from the config.ini files in the config folder.</li> <li>customise the report header in the console output.</li> <li>customising the test status words, colours and icons in the console output.</li> <li>adding a report section at end of console output.</li> <li>and more...</li> </ul> <p></p>"},{"location":"pytest/pytest_test_management/","title":"Test Management","text":""},{"location":"pytest/pytest_test_management/#using_the_test_name_as_meta_data","title":"Using the test name as meta data","text":"<p>If we name our tests with the following structure:</p> <p>test_0001_api_description</p> <p>We can programatically use the pytest_collection_modifyitems(items), where items is a list of tests, to extract out the following information:</p> <ul> <li>test id (0001).</li> <li>type of test, (api), which could be any 3 character code like dbm for database model, int for integrations, unt for unit etc</li> <li>we also get access to the nodeid and markers for each test with this hook.</li> </ul> <p>This can be loaded into a database and then combined with the output CSVs that have:</p> <ul> <li>test id</li> <li>test name</li> <li>any markers</li> <li>test node id which gives folder, parent folders up to tests folder</li> <li>test result</li> <li>test duration</li> </ul> <p>Docstrings can also be extracted and added to the database.</p>"},{"location":"pytest/pytest_test_management/#report_name_as_test_run_information","title":"Report name as test run information","text":"<p>Furthermore, as output test CSV files have the format of <code>report_2024-06-02-13-39-00_9496487.csv</code>, we can split the filename on '_'. giving us the date and time of the test from the second item. This should be globally unique as it gives the time to the second, but to ensure global uniqueness, a randon intger between, 1_000_000 and 9_999_999 is added.</p> <p>We can also include the application version as well, i.e. <code>report_V061_2024-06-02-13-39-00_9496487.csv</code>, whee V061 would indicate a development sprint 67.</p> <p>These files can then be digested and inserted into SQL tables enabling a full audit trail of tests over time and versions to be made.</p> <p>This enable these data tables to be joined to create detailed test reporting. A sprint version number can also be added to create a history of tests by sprint.</p> <p>Extending the database with test creators, creation date, test modifier and modification date, we can create audit trails of tests.</p> <p></p>"},{"location":"pytest/pytest_tests/","title":"Tests","text":""},{"location":"pytest/pytest_tests/#00_check_setup","title":"00 check_setup","text":"<p>These are used to test that:</p> <ul> <li>src and tests are wired correctly</li> <li>read config.ini in the config folder</li> <li>logging works and outputs to log/pytesting.log</li> <li>test a sample mock works</li> </ul>"},{"location":"pytest/pytest_tests/#01_inspect","title":"01 Inspect","text":"<p>Using SQLModel's inspect, we run tests on SQL schema to verify foreign keys, check constraints etc exist. Inspired by Very Academy's TDD Fast API course.</p> <p>There is also a repo and video series on YoYo database migrations and SQL Schema Tests here https://pytest-cookbook.com/toolbox/docker_postgres_yoyo_pytest/.</p>"},{"location":"pytest/pytest_tests/#02_coffeebeforearch","title":"02 CoffeeBeforeArch","text":"<p>Located in <code>02_py_coffee</code> in PFS, this is a great video series on PyTest. I have included the tests form his repo as part of the template tests. Links in repo.</p> <p>CoffeeBeforeArch</p>"},{"location":"pytest/pytest_tests/#03_indian_pythonista","title":"03 Indian Pythonista","text":"<p>Located in <code>03_indian_pythonista</code> in PFS, this is another great video series that has source code included.</p> <p>Indian Pythonista</p>"},{"location":"pytest/pytest_tests/#05_mocks_patch","title":"05 mocks_patch","text":"<p>A large number of templated mocks and patches, with extensive code comments. I have adapted them as necessary and the links to the YouTube videos are included.</p> <p>Some did not have source code so I transcribed the code from the videos.</p>"},{"location":"pytest/pytest_tests/#10_py_api_pets","title":"10 py_api_pets","text":"<p>Using Playwright, the full CRUD api tests to https://petstore.swagger.io/v2/pet/ is included providing templates for API testing.</p>"},{"location":"pytest/pytest_tests/#20_playwright","title":"20 playwright","text":"<p>A great range of End2End tests from a variety of sources.</p>"},{"location":"pytest/pytest_tests/#50_pwe_bdd","title":"50 pwe_bdd","text":"<p>A working example of using the pyTest-bdd, based on the awesome resource https://pytest-with-eric.com/ which is perhaps the best resource on PyTest available.</p>"},{"location":"pytest/pytest_tests/#60_pwe","title":"60 pwe","text":"<p>Using the awesome resource https://pytest-with-eric.com/, I have started to create videos of me working through Eric's articles and integrating them into PFS.</p>"},{"location":"pytest/pytest_tests/#docker","title":"Docker","text":"<p>These are tests that use/test Docker implementations. Alas, my favoured numbering system was not possible due to erroring, but is section 70.</p> <p></p>"},{"location":"toolbox/allure_windows_setup/","title":"Allure Reporting - Windows","text":"<p>If you are on Windows, like me, we can set up Allure as follows:</p> <p>I used the following video as learning:</p> <p>Useful JDK Video</p> <p>I created my own video here:</p> <p>Install JDK</p> <p>To install Allure: </p> <p>Allure Install</p> <ul> <li>For Allure, download the zip of the version you want.</li> <li>Unzip and place in a location of your choice.</li> <li>Add the path in environment variables. Mine was C:\\allure\\bin</li> </ul> <p></p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/","title":"Docker Postgres Yoyo PyTest","text":""},{"location":"toolbox/docker_postgres_yoyo_pytest/#yoyo","title":"Yoyo","text":"<ul> <li>Repo: https://github.com/Python-Test-Engineer/yt-docker-postgres-yoyo-pytest</li> <li>YouTube: due soon...</li> <li>YoYo docs: https://ollycope.com/software/yoyo/latest/</li> </ul> <p>Yoyo is a database migration tool like Alembic, except it does not use an ORM but SQL.</p> <p>In thisproject, yt-docker-postgres-yoyo-pytest, we use Docker and Postgres along with YoYo migrations to set up an ecommerce database. </p> <p>Using various SQL scripts, we can get a list of all constraints - PK, FK, Defaults, Unique and Check - which can then be used to carry out structural testing to ensure that database intgerity is preserved during development.</p> <p>YoYo acts like Git for our migrations with rollback made possible.</p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/#migrations","title":"Migrations","text":"<p><code>yoyo new -m \"add foreign keys\"</code> creates a file in the <code>migrations</code> folder that has 'steps' of SQL and their rollback. The file has a name of <code>datestamp-random_chars-message_used.py</code>.</p> <p></p> <p></p> <p>There can be many step functions in the steps list.</p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/#fix_plg_resourcs_error","title":"Fix plg_resourcs error","text":"<p>You may not get this but I had this, when I installed on Windows- it complained of 'no pkg_resources'.</p> <p>This was fixed with installing setuptools, (in requirements.txt).</p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/#yoyo_list","title":"<code>yoyo list</code>","text":"<p>This lists all migrations and their status - 'U' unapplied and 'A' applied</p> <p></p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/#after_yoyo_apply","title":"After <code>yoyo apply</code>:","text":""},{"location":"toolbox/docker_postgres_yoyo_pytest/#after_two_yoyo_rollback","title":"After two <code>yoyo rollback</code>:","text":""},{"location":"toolbox/docker_postgres_yoyo_pytest/#pgadmin_looks_like","title":"PgAdmin looks like:","text":""},{"location":"toolbox/docker_postgres_yoyo_pytest/#project_structure","title":"Project structure","text":"<p>The <code>sql_schema folder</code> contains scripts to query the schema tables for all constraints.</p> <p>The <code>steps</code> folder has just the steps for reuse and archice.</p> <p>The <code>sql_postgres</code> folder has a number of python CRUD files that connect to the docker-postgres instance to act as a set up check and utilities.</p> <p><code>yoyo.ini</code> is a configurtion file that has minimal required settings for source of yoyo migration files, (migrations usually), and the DB connection URL:</p> <pre><code>sources = %(here)s/migrations\n; both host.docker.internal and localhost work\ndatabase = postgresql://postgres:postgres@host.docker.internal/postgres?port=5432\n</code></pre> <p>In the video, you will see examples of building up a number of migration files and also how to rollback one, many or all migrations.</p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/#db_structural_testing","title":"DB Structural Testing","text":"<p>Our DB has PK, FK, Unique and Check constraints and we can access Postgres Schema to run tests on the strucure of the DB:</p> <ul> <li>Are all the tables there?</li> <li>Are all the PKs and FKs there?</li> <li>Are all the Unique and Check constraints there?</li> </ul> <p>This is in addition to CRUD testing we may do. This helps ensure that we have not damaged our DB schema during any development.</p> <p>The project also includes a folder of sql_postgress python modules to perfome CRUD etc.</p>"},{"location":"toolbox/docker_postgres_yoyo_pytest/#docker_postgres_setup","title":"Docker Postgres setup","text":"<p>It uses the standard docker-postgres-pgadmin-adminer-python-sql project to set up Docker Postgres.</p> <p></p>"},{"location":"toolbox/git_essentials/","title":"Git Essentials","text":"<p>A very good reference that is thorough yet light is https://www.atlassian.com/git/glossary#commands.</p> <p>Git commands I use most frequently in my work.</p>"},{"location":"toolbox/git_essentials/#clone_a_repo","title":"Clone a repo","text":"<pre><code>git clone &lt;repo_url&gt;\n</code></pre>"},{"location":"toolbox/git_essentials/#rename_a_branch","title":"Rename a branch","text":"<pre><code>git branch -M &lt;new_name&gt;\n</code></pre>"},{"location":"toolbox/git_essentials/#checkout_a_remote_branch","title":"Checkout a remote branch","text":"<pre><code>git checkout -b &lt;branch_name&gt; &lt;origin/branch_name&gt;\n</code></pre>"},{"location":"toolbox/git_essentials/#clear_git_cache","title":"Clear git cache","text":"<pre><code>git rm -r --cache .\n</code></pre>"},{"location":"toolbox/git_essentials/#delete_local_branch","title":"Delete local branch","text":"<pre><code>git branch -D &lt;branch_name&gt;\n</code></pre>"},{"location":"toolbox/git_essentials/#delete_remote_branch","title":"Delete remote branch","text":"<pre><code>git push origin --delete &lt;branch_name&gt;\n</code></pre>"},{"location":"toolbox/git_essentials/#list_remote_origin","title":"List remote origin","text":"<pre><code>git remote -v\n</code></pre>"},{"location":"toolbox/git_essentials/#change_url_of_remote_origin","title":"Change url of remote origin","text":"<pre><code>git remote set-url origin git@github.com:User/UserRepo.git\n</code></pre>"},{"location":"toolbox/git_essentials/#delete_remote_origin","title":"Delete remote origin","text":"<pre><code>git remote remove origin\n</code></pre>"},{"location":"toolbox/git_essentials/#add_a_remote_origin","title":"Add a remote origin","text":"<pre><code>git remote add origin &lt;remote_url&gt;\n</code></pre>"},{"location":"toolbox/git_essentials/#edit_previous_commit_message","title":"Edit previous commit message","text":"<p><pre><code>git commit --amend\n</code></pre>  - opens up git editor.</p>"},{"location":"toolbox/git_essentials/#list_checkouts_one_line","title":"List checkouts one line","text":"<pre><code>git log --pretty=oneline\n</code></pre>"},{"location":"toolbox/git_essentials/#go_back_to_a_previous_commit","title":"Go back to a previous commit","text":"<p><pre><code> git reset --soft HEAD~1\n</code></pre> Reset will rewind your current HEAD branch to the specified revision. In our example above, we'd like to return to the one before the current revision - effectively making our last commit undone.</p> <p>Note the --soft flag: this makes sure that the changes in undone revisions are preserved. After running the command, you'll find the changes as uncommitted local modifications in your working copy.</p> <p>If you don't want to keep these changes, simply use the --hard flag. Be sure to only do this when you're sure you don't need these changes anymore.</p>"},{"location":"toolbox/git_essentials/#go_back_to_the_previous_commit_hard","title":"Go back to the previous commit (hard)","text":"<pre><code>git reset --hard HEAD~1\n</code></pre>"},{"location":"toolbox/git_essentials/#go_back_to_a_particular_commit","title":"Go back to a particular commit","text":"<pre><code>git reset --hard 0ad5a7a6\n</code></pre>"},{"location":"toolbox/hatch/","title":"Hatch","text":""},{"location":"toolbox/hatch/#repo","title":"Repo","text":"<p>https://github.com/Python-Test-Engineer/yt-hatch</p>"},{"location":"toolbox/hatch/#youtube","title":"YouTube","text":"<p>https://www.youtube.com/watch?v=lmQvbLD6gXQ</p>"},{"location":"toolbox/hatch/#hatch_docs","title":"Hatch docs","text":"<p>https://hatch.pypa.io/latest/</p>"},{"location":"toolbox/hatch/#about","title":"About","text":"<p>I wanted to set up a new project using Hatch and understand how it uses environments.</p> <p>When I use Python's venv, I create a virtual environment and then run my project in that.</p> <p>Hatch lives outside of Python.</p> <p>We set up in pyproject.toml a number of environments for different use cases such as dev, linting etc.</p> <p>In the video and repo, I set up an environment that I will use during <code>dev</code> and show you a workflow for dev and testing.</p> <p></p>"},{"location":"toolbox/manage_docker_with_python/","title":"Manage Docker with Python","text":"<p>Repo: yt-docker-managed-by-python</p> <p>Video: to follow...</p> <p>There are two main libraries for this:</p> <ol> <li>Docs: Python on Whales</li> <li>Docs: Docker Py</li> </ol> <p>For Python on Whales, a very useful script is:</p> <p><pre><code>from python_on_whales import DockerClient\n\ndocker = DockerClient(compose_files=[\"../docker-compose.yml\"])\n\ndocker.compose.build()\ndocker.compose.up(detach=True)\n\n# docker.compose.down()\n</code></pre> By using a docker-compose.yaml file, we can use PyYaml to read, write and edit these files, enabling programatic customisation and creation of containers.</p> <p>Another example is : <pre><code>docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres\n</code></pre> becomes <pre><code>from python_on_whales import docker\n\ndocker.run(\n    \"postgres:9.6\",\n    name=\"some-postgres\",\n    envs={\"POSTGRES_PASSWORD\": \"mysecretpassword\"},\n    detach=True,\n)\nprint(docker.ps())\n# [python_on_whales.Container(id='f5fb939c409d', name='some-postgres')]\n</code></pre> which can also be managed programatically.</p> <p>For Docker-Py we have:</p> <pre><code>import docker\nclient = docker.from_env()\nimage = client.images.pull(\"redis\")\noutput = client.containers.run(\"ubuntu\", \"echo hello world\")\noutput = output.decode(\"utf-8\")\nprint(str(output))\n\ncontainers = client.containers.list()\nfor container in containers:\n    print(container.name)\nPORT = random.randint(8000, 9000)\ncontainer = client.containers.run(\"nginx:latest\", detach=True, ports={\"80/tcp\": PORT})\n</code></pre> <p>Docker enables the use of ARG and --build-arg to add arguments prior to FROM, FROM usually being the first allowed command</p> <p><pre><code>ARG BaseImage\nFROM $BaseImage\n</code></pre> and this means we can use this and other shell variables to script a lot of processes and create our own testing matrix.</p> <p>For the Docker Py library we have:</p> <pre><code>import docker\nclient = docker.from_env()\nimage = client.images.pull(\"redis\")\noutput = client.containers.run(\"ubuntu\", \"echo hello world\")\noutput = output.decode(\"utf-8\")\nprint(str(output))\n\ncontainers = client.containers.list()\nfor container in containers:\n    print(container.name)\nPORT = random.randint(8000, 9000)\ncontainer = client.containers.run(\"nginx:latest\", detach=True, ports={\"80/tcp\": PORT})\n</code></pre> <p>Sources of YT video on Python and YAML</p> <ol> <li> <p>MathByte - shorter and more concise video with its repo installed in this project in <code>yaml</code> folder.</p> </li> <li> <p>DevOpsMadeEasy which has a YT video (1hr 45m) here.</p> </li> </ol> <p>The repo and video explore managing Docker programatically with Python, mostly through the use of editing docker compose files and then running them programatically.</p> <p></p>"},{"location":"toolbox/pydantic_dts/","title":"Pydantic Data Transformation Services","text":"<p>\"Today, Pydantic is downloaded many times a month and used by some of the largest and most recognisable organisations in the world.</p> <p>It's hard to know why so many people have adopted Pydantic since its inception six years ago, but here are a few guesses.\"</p> <p></p> <p>DESERIALIZATION === input string/dict/JSON data into Pydantic Python Models</p> <p>SERIALIZATION === output data from Pydantic Python Model to string/dict/JSON data</p>"},{"location":"toolbox/pydantic_dts/#lifecycles","title":"Lifecycles","text":""},{"location":"toolbox/pydantic_dts/#before","title":"Before","text":"<p>If we are importing in JSON for example, we can create aliases so that we can map firstName to first_name for example. We can also set rules for how Pydantic should handle extra fields.</p> <p>We can also apply validation and data transformation prior to Pydantic carry out its own validataion, transformation and insertion.</p>"},{"location":"toolbox/pydantic_dts/#pydantic_validation","title":"Pydantic validation","text":"<p>Our Pydantic model will validate data and return a list of errors that fail validation.</p> <p>Pydantic does not stop on the first failed validation but continues on until all fields have been validated and it will then report a list of all validation errors.</p>"},{"location":"toolbox/pydantic_dts/#after","title":"After","text":"<p>After Pydantic has run thorugh its own process, we can apply after validators/transformations prior to being inserted into the class.</p>"},{"location":"toolbox/pydantic_dts/#serialization","title":"Serialization","text":"<p>When serialising, ('exporting'), we can set up rules for include/exclude fields depending on whether we are exporting to a Python dict or JOSN object.</p>"},{"location":"toolbox/pydantic_dts/#ingesting_a_rest_api","title":"Ingesting a REST API","text":"<p>Using <code>https://dummyjson.com/users/3</code> we get a dictionary from our requests library.</p> <ul> <li><code>01_user.py</code> - set up model level configuration and filter API for just a few fields.</li> <li><code>02_user_composition.py</code> - we use nested models for our <code>address</code> field.</li> <li><code>03_user_field_validation.py</code> - we apply field level validation/transformation on the <code>last_name</code> field and also demonstrate ordering of decorators where we use many on on field:</li> </ul> <p> </p> <p>No matter what order the validators are lexcially defined in, the order is always Before first with furthest lexically first, then After with lexically nearest first.</p>"},{"location":"toolbox/pydantic_dts/#repo","title":"Repo","text":"<p>https://github.com/Python-Test-Engineer/yt-pydantic-dts</p>"},{"location":"toolbox/pydantic_dts/#youtube_video","title":"YouTube Video","text":"<p>https://www.youtube.com/playlist?list=PLsszRSbzjyvnRLSoGM3e-VspqImbWpXSL</p>"},{"location":"toolbox/pydantic_dts/#best_course_on_pydantic","title":"Best course on Pydantic","text":"<p>https://www.udemy.com/course/pydantic and there is a very good YT video by him https://www.youtube.com/watch?v=ok8bF8M7gjk which he also has a  repo for in the links.</p> <p></p>"},{"location":"toolbox/rich_pyboxen/","title":"Rich and Pyboxen","text":""},{"location":"toolbox/rich_pyboxen/#rich","title":"Rich","text":"<p>We can format the console using a very powerful library, Rich https://rich.readthedocs.io/en/latest/index.html.</p> <p> <pre><code>from rich import print\n\nprint(\"Hello, [bold magenta]World[/bold magenta]!\", \":vampire:\", locals())\n</code></pre> </p> <p>For a more pretty traceback:</p> <p><pre><code>from rich.traceback import install\ninstall(show_locals=True)\n</code></pre> </p> <p>A range of templates are available in Rich's GitHub repo here.</p>"},{"location":"toolbox/rich_pyboxen/#pyboxen","title":"PyBoxen","text":"<p>PyBoxen is built on Rich and provides quick boxes - https://github.com/savioxavier/pyboxen.</p> <p><pre><code>from pyboxen import boxen\n\nprint(\n    boxen(\n        \"Titles and subtitles!\",\n        title=\"Hello, [black on cyan] World [/]\",\n        subtitle=\"Cool subtitle goes here\",\n        subtitle_alignment=\"center\",\n        color=\"yellow\",\n        padding=1,\n    )\n)\n</code></pre> </p> <p></p>"},{"location":"toolbox/toolbox_index/","title":"Toolbox","text":"<p>This is a colelction of resources that are of use as a Python Test Engineer but are not part of PyTest Full Stack. </p> <p>They are self-contained units.</p> <p>Docker plays are a large part in the Toolbox and may end up having its own dedicated section.</p>"},{"location":"toolbox/visual_regression/","title":"Visual Regression","text":"<p>We can test whether two images are equal or how much they differ by on a pixel by pixel basis.</p> <p>We use the library <code>pixelmatch</code> https://pypi.org/project/pixelmatch/.</p>"},{"location":"toolbox/visual_regression/#youtube","title":"YouTube","text":"<p>https://www.youtube.com/watch?v=wMjsrsQK3hs</p>"},{"location":"toolbox/visual_regression/#repo","title":"Repo","text":"<p>https://github.com/Python-Test-Engineer/yt-visual-regression</p>"},{"location":"workshop/afterwards/","title":"Afterwards","text":""},{"location":"workshop/afterwards/#cookbook","title":"Cookbook","text":"<p>The cookbook covers many more items such as:</p> <ul> <li>Docker</li> <li>Asides on Mocking and Pluggy</li> <li>Toolbox for Console Prettying using Rich and PyBoxen, Allure reports, Visual Regression etc and I add more content as time passes.</li> </ul>"},{"location":"workshop/afterwards/#revision","title":"Revision","text":"<p>CoffeeBeforeArch and Indian Pythonista are very good concise walkthroughs of PyTest covering beginner to advanced topics.</p>"},{"location":"workshop/afterwards/#development","title":"Development","text":"<p>PyTestWithEric, has probably the best set of articles and repos covering beginner to advanced topics and I have created videos of them and incorporating the GitHub code to provide a second content delivery medium, explaining salient points.</p> <p>Python Testing with pytest, Second Edition Simple, Rapid, Effective, and Scalable by Brian Okken</p> <p>The definitive book!</p> <p></p> <p>https://pragprog.com/titles/bopytest2/python-testing-with-pytest-second-edition/</p>"},{"location":"workshop/afterwards/#online_hooks_and_plugins","title":"Online Hooks and Plugins","text":"<p>For an advanced look at these topics, I have my course hosted on Udemy:</p> <p>The link and coupon code are available for the next 3 days: HERE</p> <p>The course is available Udemy Hooks and Plugins course.</p> <p></p> <p>The repo contains heavily commented source files creating a sort of 'ebook' and is freely available https://github.com/Python-Test-Engineer/Udemy-PyTest. The video course add visual explanations and commentary.</p>"},{"location":"workshop/afterwards/#reach_out","title":"Reach out","text":"<p>I am contactable via the links at pytest-cookbook.com.</p> <p></p>"},{"location":"workshop/build_from_scratch/","title":"Build from scratch","text":"<p>We have already seen the BASIC demo and the minimum we need to use pytest is a <code>tests</code>folder with test files <code>test_*.py</code> and pytest installed. This will enable us to do <code>python -m pytest</code> to run tests.</p> <p>We will cover how to use the plugins in PyTest 102.</p> <p>To build the PFS framework we can add the following:</p>"},{"location":"workshop/build_from_scratch/#src","title":"src","text":"<p>Folder for one's source code - optional but recommended location by Python.</p> <p>We will assume we have our <code>src</code> folder.</p> <p>We can create a virtual environment with <code>python -m venv venv</code> followed by activation:</p> <ul> <li><code>.\\venv\\scripts\\activate</code> for Windows</li> <li><code>source venv/bin/activate</code> for Mac and Linux</li> </ul>"},{"location":"workshop/build_from_scratch/#pytest","title":"PyTest","text":"<p>Installation of <code>pytest</code> with <code>pip install pytest</code>.</p>"},{"location":"workshop/build_from_scratch/#playwright","title":"Playwright","text":"<p>Installation of Playwright<code>pip install playwright</code> and also <code>plyawright install</code> to load browsers for headed tests.</p>"},{"location":"workshop/build_from_scratch/#pytestini","title":"pytest.ini","text":"<p>Holds settings for PyTest.</p> <p>We can use the one in PFS deleting unwanted entries.</p>"},{"location":"workshop/build_from_scratch/#log_folder","title":"log folder","text":"<p>Folder to store <code>pytest.log</code> file for logging messages as defined in <code>pytest.ini</code>.</p> <pre><code># for log file - pytest uses these whenever logger used\n# boiler plate code that can be changed to suit\n\nlog_file = log/pytesting.log # customise as required\nlog_file_level = INFO\nlog_file_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s (%(filename)s:%(lineno)s)\nlog_file_date_format=%Y-%m-%d %H:%M:%S\n</code></pre> <p>In PFS, the logging location is <code>log</code> so we create this folder.</p> <p>For reference only:</p> <p>https://docs.pytest.org/en/8.3.x/contents.html</p> <p></p>"},{"location":"workshop/build_from_scratch/#utils_folder","title":"utils folder","text":"<p>Utility functions are stored in <code>utils</code>.</p>"},{"location":"workshop/build_from_scratch/#config_folder","title":"config folder","text":"<p>Folder that holds <code>*.ini</code> files or other config files. We create a <code>config</code> folder.</p> <p>This can be useful as an alternative to CLI arguments. We can add our options in the config.ini file to be retrieved in our tests using the <code>read_config.py</code> file. </p> <p>This is standard Python.</p>"},{"location":"workshop/build_from_scratch/#results_folder","title":"results folder","text":"<p>Our custom CSV ouput files will go here based on the settings in the root <code>conftest.py</code> file, (near top of file), in the tests folder:</p> <pre><code># ----- OUTPUT FILE AND LOCATION -----\nreport_date = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n# practically a GUID...\nFILENAME = f\"./results/report_{report_date}_{random.randint(1_000_000, 9_999_999)}.csv\"\n</code></pre>"},{"location":"workshop/build_from_scratch/#reports_folder","title":"reports folder","text":"<p>This is where we store our pytest-html reports, but we can choose any folder but we will use <code>reports</code> as in PFS.</p> <p>We need to <code>pip install pytest-html</code>.</p>"},{"location":"workshop/build_from_scratch/#htmlcov_folder","title":"htmlcov folder","text":"<p>We need to <code>pip install pytest-cov</code>.</p> <p>Coverage report from pytest-cov can go here depending if we use <code>pytest --cov=htmlcov tests/</code>.</p> <p>A <code>.coverage</code> report file is produced in the root of the project. </p>"},{"location":"workshop/build_from_scratch/#pytest-xdist","title":"pytest-xdist","text":"<p>To speed up tests we <code>pip install pytest-xdist</code>.</p>"},{"location":"workshop/build_from_scratch/#screenshots_folder","title":"screenshots folder","text":"<p>We add a <code>screenshots</code> folder, (or any name we choose). We may also do this for videos and traceback if we are using these Playwright features.</p> <p><code>test_08_download.py</code> uses the <code>screenshot</code> folder.</p>"},{"location":"workshop/build_from_scratch/#tests","title":"Tests!","text":"<p>All our tests are stored in the <code>tests</code> folder.</p> <p>We don't need to add <code>__init__.py</code> in this folder or subfolders but if we don't, we may have a test name collision if two tests have the same name.</p>"},{"location":"workshop/build_from_scratch/#pfs","title":"PFS","text":"<p>With all of these, we have replicated PFS, although we may choose to add Rich and Pyboxen for colorisation etc.</p> <p></p>"},{"location":"workshop/final_project/","title":"Final Project, PFS","text":""},{"location":"workshop/final_project/#minimal_setup","title":"Minimal Setup","text":"<p>Whilst PyTest and PFS have many features, a basic set up suffices:</p> <ul> <li>Install PyTest.</li> <li>Create a <code>tests</code> folder and module named <code>test_XXX.py</code> with test starting with <code>def test_</code>.</li> <li>Run <code>python -m pytest -v</code> (-m run as module, -v verbose).</li> </ul> <p>I will demonstrate this with the BASIC example.</p>"},{"location":"workshop/final_project/#installation","title":"Installation","text":"<p>We will start by downloading and setting up PFS so that you have a working final project to take away.</p> <p>We will look at its structure and customisation and then move on to building it from scratch if necessary. Some of this may be done later in the workshop but we will see what we are able to do.</p> <ul> <li><code>git clone https://github.com/Python-Test-Engineer/PyTest-Full-Stack</code></li> <li>Create virtual enviroment <code>python -m venv venv</code></li> <li>Activate your virtual enviromnent: Windows <code>.\\venv\\Scripts\\activte</code> or Mac <code>source venv/bin/activate</code>.</li> <li>install requirements <code>pip install -r requirements.txt</code>.</li> <li>for Playwright browsers run <code>playwright install</code>.</li> <li>There are around 200 templated tests.</li> </ul>"},{"location":"workshop/final_project/#rich_and_pyboxen","title":"Rich and PyBoxen","text":"<p>I use Rich, (mostly), and PyBoxen, which is based on Rich to colorise console output.</p> <p>More details at https://pytest-cookbook.com/toolbox/rich_pyboxen/.</p>"},{"location":"workshop/final_project/#test_run","title":"Test run","text":"<p>Let's run <code>python -m pytest -vs -n auto --headed</code>. </p> <p>The <code>-n auto</code> uses pytest-xdist to determine number of cores and split tests across them. One can set number of cores <code>-n 4</code> etc.</p> <p>Try running PFS without the -n flag or change the number of cores used.</p> <p>The <code>--headed</code> tells Playwright to open up browsers in our E2E tests for demonstraion puposes. Generally, headless tests are used.</p> <p>We can see a CSV of results in the <code>results</code> folder. The console ouput is colorised with the Rich library. Rename the <code>conftest.py</code> in the root of the folder to say <code>Xconftest.py</code> and you will see no CSV produced and no colorisation.</p>"},{"location":"workshop/final_project/#customisation","title":"Customisation","text":"<p>YouTube playlist: here</p> <p>This covers:</p> <ul> <li>pytest.ini settings for logging.</li> <li>how to read values from the config.ini files in the config folder.</li> <li>customise the report header in the console output.</li> <li>customising the test status words, colours and icons in the console output.</li> <li>adding a report section at end of console output.</li> <li>and more...</li> </ul> <p>The free online course 'PyTest Hooks and Plugins' that you have a free coupon for goes into much more detail about how to use hooks in PyTest.</p> <p></p>"},{"location":"workshop/pytest_101/","title":"PyTest 101","text":""},{"location":"workshop/pytest_101/#test_discovery","title":"Test discovery","text":"<p>Before we look at the body of a test, we will first look at naming conventions of test function, classes, files and folders.</p> <p>The default folder is <code>tests</code>. We can configure testpaths in <code>pytest.ini</code> for PyTest to search the listed folders: <pre><code>testpaths =\n    tests\n    integration\n</code></pre> Do we need <code>__init__.py</code> in <code>tests</code> folder/subfolders?</p> <p>No. But if we don't and two tests have same name then there will be a name collision.</p> <p>Using <code>__init__.py</code> will make each test have a unique namespace.</p>"},{"location":"workshop/pytest_101/#conventions","title":"Conventions","text":"<p>https://docs.pytest.org/en/stable/example/pythoncollection.html</p> <p></p> <p>https://docs.pytest.org/en/stable/explanation/goodpractices.html#conventions-for-python-test-discovery</p> <p>We can change default in <code>pytest.ini</code>:</p> <p></p>"},{"location":"workshop/pytest_101/#create_a_test","title":"Create a test","text":""},{"location":"workshop/pytest_101/#function_based","title":"Function based","text":"<p>If we have a function <code>src\\some_function.py</code> and we want to test it, we can run this function within a test and PyTest will excute it and store results etc:</p> <pre><code>def test_some_function_works.py():\n    actual_result = some_function()\n    expecterd_result = \"expected result values here\"\n    assert actual_result == expected_result, \"(optional) output message if not equal\"\n</code></pre>"},{"location":"workshop/pytest_101/#class_based","title":"Class based","text":"<p>Using a class based test can group tests together and we can also apply PyTest features to the class and thus all the methods in it.</p> <p>For discovery, both the class and methods must follow the naming convention whether default or custom.</p> <p>(see above)</p> <p>For class: Test*</p> <p>For methods test_ or _test</p> <pre><code>class TestSample:\n\n    def test_0031_SET_add_num(self):\n        \"\"\"fn test in a class\"\"\"\n        assert add(1, 2) == 3\n\n    def test_0032_SET_add_num_will_fail(self):\n        \"\"\"failing fn test in a class\"\"\"\n        console.print(\"[red italic]Example of failed test[/]\u26a0\ufe0f\")\n        assert add(1, 2) == 5\n</code></pre>"},{"location":"workshop/pytest_101/#run_a_test","title":"Run a test","text":"<p>To run tests we run <code>python -m pytest</code>. We can run just <code>pytest</code> but running it as a module adds the path to sys.path and can avoid any future issues.</p> <p> https://docs.pytest.org/en/stable/how-to/usage.html#other-ways-of-calling-pytest</p> <p>I use Rich and PyBoxen for console colouring. Some notes are here https://pytest-cookbook.com/toolbox/rich_pyboxen/.</p> <p>Let's run two tests, one PASSED and one FAILED...</p> <p>In <code>00_check_setup\\test_01_setup.py</code> there are two tests:</p> <pre><code>def test_0001_SET_pass():\n    sleep(1)\n    console.print(\"\\n[blue bold]Testing Rich[/]\\n\")\n    assert True\n\n# A test fail to show as an example\ndef test_0004_SET_this_will_fail():\n    console.print(\"[red italic]Example of a failed test[/]\u26a0\ufe0f\")\n    assert False\n</code></pre> <p>A failed test with -v verbosity gives: </p> <p>We will look at verbosity and outputs later...</p> <p>We can run this easily with <code>python -m pytest -vs -k 0001</code> (-k is a 'like' and with unique test numbering it can be a convenient way to select a test, which we will dive into this deeper later...).</p> <p>I will explain my test naming convention later...</p>"},{"location":"workshop/pytest_101/#selecting_tests","title":"Selecting tests","text":""},{"location":"workshop/pytest_101/#locations","title":"Locations","text":"<p>We can select tests by their location, module, class or function:</p> <p> https://docs.pytest.org/en/stable/how-to/usage.html#specifying-which-tests-to-run</p> <p>These are called nodes:</p> <p><code>python -m pytest .\\tests\\00_check_setup\\test_01_setup.py</code></p> <p><code>python -m pytest .\\tests\\00_check_setup\\test_01_setup.py::test_0001_SET_pass</code></p> <p><code>python -m pytest -vs .\\tests\\00_check_setup\\test_04_class_based.py::TestSample::test_0031_SET_add_num</code></p>"},{"location":"workshop/pytest_101/#-k_for_like","title":"-k for 'like'","text":"<p>We can select test that are 'like' with the <code>-k</code> option:</p> <p><code>python -m pytest -k 0001</code> to select a specific id or</p> <p><code>python -m pytest -k SET</code> will select all those that contain 'SET' in test name.</p> <p>We can combine 'not', 'or', 'and':</p> <p><code>python -m pytest -vs -k \"0211 or 0212\"</code> - note that single or double quotes are needed.</p> <p><code>python -m pytest -k \"not SQL\"</code> will get all tests that contain SET (case insensitive) or SQL. </p> <p>This can get tricky for more complex queries and in those case we will use 'markers' particularly as we can create dynamic markers that are based on Python list manipulation. We will se this later.</p>"},{"location":"workshop/pytest_101/#tests_to_runtxt","title":"@tests_to_run.txt","text":"<p>To</p> <p></p>"},{"location":"workshop/pytest_101/#markers","title":"Markers","text":""},{"location":"workshop/pytest_101/#definition","title":"Definition","text":"<p>Markers are 'tags' which we can add to tests using <code>@pytest.mark.tag_name</code> and we can then select a particular marker using <code>pytest -m pytest -m tag_name</code>.</p> <p>They are decorators and they are syntactic sugar for passing a function to another function:</p> <pre><code>def make_pretty(func):\n\n    def inner():\n        print(\"I got decorated\")\n        func()\n    return inner\n\n@make_pretty\ndef ordinary():\n    print(\"I am ordinary\")\n\nordinary()  \n\nThis is actually:\n\nordinary = make_pretty(ordinary)\n</code></pre> <p>We can assign the name of the marker after @pytest.mark</p> <p><pre><code>import pytest\n\n@pytest.mark.tag_name # needs to be imported\ndef test_use_marker_tag_name():\n    assert True\n</code></pre> Like the <code>-k</code> option, we can use add/or/not:</p> <p><code>python -m pytest -m 'outer or inner'</code></p>"},{"location":"workshop/pytest_101/#classes_and_modules","title":"Classes and modules","text":"<p>https://docs.pytest.org/en/stable/example/markers.html#marking-whole-classes-or-modules</p> <p></p>"},{"location":"workshop/pytest_101/#registering","title":"Registering","text":"<p>We do not need to register them with <code>pytest.ini</code> provided we do not have <code>--strict-markers</code> in <code>addopts</code>. If we do, we will get an error, if we don't we will get warnings.</p> <p>In our <code>pytest.ini</code> we have:</p> <pre><code>markers =\n    ;add markers of group tests - can use\n    ; after colon is optional description\n    setup: set up tests\n    sanity: sanity tests\n    mocks: all mocks\n    joke_mocks: mocks for jokes\n    add: test add\n    inner_marker: an inner marker\n    outer_marker: an outer marker\n    outer\n    inner\n    deposit\n    withdrawal\n    banking\n</code></pre> <p>In this case above, if we have  <pre><code>addopts = --strict-markers\n</code></pre> then any markers not registered will cause an error.</p>"},{"location":"workshop/pytest_101/#calling_markers","title":"Calling markers","text":"<p>If we run <code>python -m pytest -m sanity</code> we will get all those that have a marker of <code>sanity</code>.</p> <p>We can also use <code>not</code>: <code>python -m pytest -m \"not sanity\"</code></p> <p>We can also mark a whole Class and all method tests within will be selected.</p>"},{"location":"workshop/pytest_101/#multiple_markers","title":"Multiple markers","text":"<p>Multiple markers: https://github.com/pytest-dev/pytest/issues/6142</p> <p><code>python -m pytest -m \"sanity or outer\"</code> will select all tests with either <code>sanity</code> or <code>outer</code> as marks. It works in the same way as the <code>-k</code> flag and we can use <code>not</code> and <code>and</code>.</p>"},{"location":"workshop/pytest_101/#dynamic_markers","title":"Dynamic markers","text":"<p>We will not discuss this yet but it is worth mentioning because managing 500+ test markers is best done dynamically...</p> <p>We can use a hook <code>pytest_collect_modifyitems()</code>...</p>"},{"location":"workshop/pytest_101/#built_in_markers","title":"Built in markers","text":""},{"location":"workshop/pytest_101/#pytestmarkskip","title":"@pytest.mark.skip","text":"<p>Rather than comment out tests, we can mark them to be skipped and they will not be selected. </p>"},{"location":"workshop/pytest_101/#pytestmarkskipif","title":"@pytest.mark.skipif","text":"<p>We can skip conditionally:</p> <pre><code>@pytest.mark.skipif(\n    sys.version_info &gt; (3, 6), reason=\"Test requires Python version &lt;= 3.6!\"\n)\n</code></pre>"},{"location":"workshop/pytest_101/#pytestmarkxfail","title":"@pytest.mark.xfail","text":"<p>We may have a test that we know will fail but we want to consider that a pass.</p> <p>We can <code>xfail</code> the test and it will not result in a failed test but be marked as an <code>xfail</code>.</p> <p>What if the <code>xfail</code> actually passes? We want to know this and it will be marked not as a fail but an <code>xpass</code> - unexepectedly passes.</p> <p>There are examples of this in the set of tests we ran on PFS at start.</p> <p>Some more detailed information is here: https://docs.pytest.org/en/stable/how-to/skipping.html#xfail-mark-test-functions-as-expected-to-fail</p> <p></p>"},{"location":"workshop/pytest_101/#markers_for_fixtures","title":"Markers for fixtures","text":"<p>We will cover this when we look at fixtures.</p>"},{"location":"workshop/pytest_101/#output_options","title":"Output options","text":"<p>https://docs.pytest.org/en/8.2.x/how-to/output.html#managing-pytest-s-output</p> <p><pre><code>pytest --showlocals     # show local variables in tracebacks\npytest -l               # show local variables (shortcut)\npytest --no-showlocals  # hide local variables (if addopts enables them)\n\npytest --capture=fd  # default, capture at the file descriptor level\npytest --capture=sys # capture at the sys level\npytest --capture=no  # don't capture\npytest -s            # don't capture (shortcut)\npytest --capture=tee-sys # capture to logs but also output to sys level streams\n\npytest --tb=auto    # (default) 'long' tracebacks for the first and last\n                     # entry, but 'short' style for the other entries\npytest --tb=long    # exhaustive, informative traceback formatting\npytest --tb=short   # shorter traceback format\npytest --tb=line    # only one line per failure\npytest --tb=native  # Python standard library formatting\npytest --tb=no      # no traceback at all\n</code></pre> We can run <code>python -m pytest -k 0004 --tb=no</code> to see a failed test with various tracebck levels.</p> <p>This may be useful when needed: </p>"},{"location":"workshop/pytest_101/#verbosity","title":"Verbosity","text":"<p>We can use one of these flags for increasing verbosity:</p> <p>-v, -vv, -vvv</p>"},{"location":"workshop/pytest_101/#console_ouput","title":"Console ouput","text":"<p>By default, PyTest suppresses console output to avoid 'clutter'.</p> <p>If we want to use <code>print</code> statements, we need to use the <code>-s</code> flag. It can be combined with the <code>-v</code> flag <code>-vs</code> which is what I tend to use by default.</p>"},{"location":"workshop/pytest_101/#-q_for_quiet","title":"-q for quiet","text":"<p>This means 'quiet'.</p>"},{"location":"workshop/pytest_101/#---durations","title":"---durations","text":"<p>https://docs.pytest.org/en/8.3.x/how-to/usage.html#profiling-test-execution-duration</p> <p></p> <p>NB We have our CSV report that gives duration for each test so that we can create our own 'durations' report.</p>"},{"location":"workshop/pytest_101/#-x_---maxfail","title":"-x ---maxfail","text":"<pre><code>pytest -x            # stop after first failure\npytest --maxfail=2   # stop after two failures\n</code></pre>"},{"location":"workshop/pytest_101/#---setup-show","title":"---setup-show","text":"<p>Used to see the order of execution.</p>"},{"location":"workshop/pytest_101/#---collectonly","title":"---collectonly","text":"<p>This will show what tests will be run without running tess.</p>"},{"location":"workshop/pytest_101/#-r_for_report","title":"-r for report","text":"<p>https://docs.pytest.org/en/8.2.x/how-to/output.html#producing-a-detailed-summary-report</p> <pre><code>f - failed\nE - error\ns - skipped\nx - xfailed\nX - xpassed\np - passed\nP - passed with output\n\nSpecial characters for (de)selection of groups:\n\na - all except pP\nA - all\nN - none, this can be used to display nothing (since fE is the default)\n</code></pre> <p>If we run <code>pytestpython -m pytest .\\tests\\00_check_setup\\ -rx</code> we get a short test summary at end of test run of just XFAIL:</p> <p></p>"},{"location":"workshop/pytest_101/#csv_outputs","title":"CSV Outputs","text":"<p>https://pytest-cookbook.com/pytest/pytest_test_management/ has more detail on test management and the use of a test naming convention.</p> <p>We can use <code>pytest-csv</code> but our custom local plugin <code>conftest.py</code> can do this for us.</p> <p>There is an explainer video for this and we will look at this a bit later and a sample line is:</p> <pre><code>0001|test_0001_SET_pass|tests/00_check_setup/test_01_setup.py::test_0001_SET_pass|PASSED|1.013291|\n</code></pre> <p>This is <code>test_id|test_name|test_node|result|duration</code>.</p> <p>Given these details and the name of the CSV file containing the run_date and unique run_id, we can do a range of reports on our tests over many differing runs.</p> <p>These can be loaded into and SQL DB to provide comprehensive analysis.</p> <p>We can use other Python libraries to analyse and display this data.</p>"},{"location":"workshop/pytest_101/#html_reports","title":"HTML Reports","text":"<p>We can also create an html report with <code>pytest-html</code>. A sample report is in the <code>reports</code> folder.</p> <p>We can run this with <code>python -m pytest --html=reports/report.html --self-contained-html</code> (see COMMANDS.md in root folder).</p>"},{"location":"workshop/pytest_101/#coverage_reports","title":"Coverage Reports","text":"<p>With <code>python -m pytest --cov-report html --cov .</code> (note end .) we get a coverage report as seen in the folder <code>htmlcov</code>.</p> <p>There is a <code>.coverage</code> file created in the root of the project which requires processing, as done by the above command to give the folder <code>htmlcov</code> with an <code>index.html</code>.</p> <p></p>"},{"location":"workshop/pytest_102/","title":"PyTest 102","text":""},{"location":"workshop/pytest_102/#fixtures","title":"Fixtures","text":""},{"location":"workshop/pytest_102/#definition","title":"Definition","text":"<p>https://docs.pytest.org/en/stable/explanation/fixtures.html</p> <p>Fixtures are requested by test functions or other fixtures by declaring them as argument names.</p> <p>They are an example of dependency injection and replace the setup/teardown features of Unit Test.</p> <p>Fixtures can thus use other fixtures. They are Python functions and can be the arguments of other functions.</p>"},{"location":"workshop/pytest_102/#implementation","title":"Implementation","text":"<p><code>tests\\02_py_coffee\\02_fixtures\\00_basic_fixtures\\test_fiztures_0.py</code> is an example:</p> <pre><code>@pytest.fixture\ndef initial_value():\n    return 5\n\ndef square(num) :\n    return num * num\n\n# We pass in the fixture - dependency injection\ndef test_0240_FXT_square(initial_value):\n    result = square(initial_value)\n    assert result == initial_value**2\n</code></pre> <p>We can rename fixtures:</p> <pre><code>@pytest.fixture\ndef initial_value(name=\"custom_name\"):\n    return 5\n\ndef test_0240_FXT_square(custom_name)\n    ...\n</code></pre>"},{"location":"workshop/pytest_102/#pytest_--fixtures","title":"pytest --fixtures","text":"<p><code>pytest --fixtures</code> is used to list available fixtures and where the fixture is located.</p>"},{"location":"workshop/pytest_102/#setupteardown","title":"setup/teardown","text":"<p>We can use <code>setup_method()</code> and <code>teardown_method()</code> as a simpler but less DRY alternative. See <code>tests\\00_check_setup\\test_04_src.py</code>.</p>"},{"location":"workshop/pytest_102/#yield_and_addfinalizer","title":"Yield and addfinalizer()","text":"<pre><code>@pytest.fixture()\ndef my_object_fixture():\n    print(\"Yielding fixture data...\")\n    yield MyObjectThatRequiresCleanUp()\n    print(\"Do clean up after test has run...\")\n</code></pre> <pre><code>@pytest.fixture\ndef setup_data(request):\n    # setup_data is now the fixture name we pass into our test...\n    print(\"\\nSetting up resources...\")\n    data = 22\n\n    # Define a finalizer function for teardown\n    def finalizer():\n        print(\"\\nPerforming teardown...\")\n        # Clean up any resources if needed\n\n    # Register the finalizer to ensure cleanup\n    request.addfinalizer(finalizer)\n\n    return data  # Provide the data to the test\n</code></pre>"},{"location":"workshop/pytest_102/#built_in_fixtures","title":"Built in fixtures","text":"<p>There are many built in fixtures provided by PyTest but I only use a few of them:</p> <p>https://docs.pytest.org/en/stable/reference/fixtures.html#built-in-fixtures </p> <p>Fixture availability is determined from the perspective of the test. A fixture is only available for tests to request if they are in the scope that fixture is defined in. If a fixture is defined inside a class, it can only be requested by tests inside that class. But if a fixture is defined inside the global scope of the module, then every test in that module, even if it\u2019s defined inside a class, can request it.</p>"},{"location":"workshop/pytest_102/#conftest","title":"Conftest","text":"<p><code>conftest.py</code> is automatically discovered and registered by PyTest. It is a good place to store fixtures so that they can be reused in the folder it is located in and any subfolders.</p> <p>It does not need to be imported.</p> <p>If a fixture appears in many <code>conftest.py</code> files then the closest <code>conftest.py</code> file to the test is used.</p> <p>Example is: <code>02_py_coffee\\02_fixtures\\test_conftest_2</code> demonstrating that the closest <code>conftest.py</code> fixture value is used. </p>"},{"location":"workshop/pytest_102/#parametrization","title":"Parametrization","text":"<p>We may want to run a test for a range of values, e.g, we may want to test our <code>add()</code> for a range of values.</p> <p>Rather than do some Pythonic looping over a test, we can use the <code>@pytest.mark.parametrize()</code> to decorate the test and supply our values in this decorator.</p> <p>A decorator is a function that wraps another function and any values passed into the deocrator are available to the inner function by the closure created.</p>"},{"location":"workshop/pytest_102/#examples","title":"Examples","text":"<ul> <li><code>tests\\03_indian_pythonista\\ip_04_parametrize\\tests\\test_sample.py</code></li> <li><code>python -m pytest -vs -k TestClassSetUp</code></li> </ul> <pre><code>n and expected are variable names that take values of supplied list\n@pytest.mark.parametrize(\"n, expected\", [(1, 2), (3, 4)])\nclass TestClass:\n    def test_simple_case(self, n, expected):\n        assert n + 1 == expected\n\n    def test_weird_simple_case(self, n, expected):\n        assert (n * 1) + 1 == expected\n</code></pre>"},{"location":"workshop/pytest_102/#output","title":"Output","text":""},{"location":"workshop/pytest_102/#options","title":"Options","text":"<p>There are a great many options available:</p> <ul> <li>Add ids for more human readable output.</li> <li>Using the indirect=True parameter when parametrizing a test allows to parametrize a test with a fixture receiving the values before passing them to a test.</li> </ul>"},{"location":"workshop/pytest_102/#customisation_by_hooks","title":"Customisation by hooks","text":""},{"location":"workshop/pytest_102/#plugins","title":"Plugins","text":"<p>These are some of the most common plugins.</p> <p>xdist aside, we can recreate some of the functionality through the use of hooks. The online course 'PyTest Cookbook - Using hooks to create plugins' that you will have a free coupon for will go through this in much more details.</p> <p>It is easier than one might think!</p>"},{"location":"workshop/pytest_102/#pytest-csv","title":"pytest-csv","text":"<p>We already create our own cutomisable CSV output.</p>"},{"location":"workshop/pytest_102/#pytest-html","title":"pytest-html","text":""},{"location":"workshop/pytest_102/#pytest-cov","title":"pytest-cov","text":"<p>Coverage is an important metric.</p> <p>https://pytest-with-eric.com/coverage/poetry-test-coverage/ is a very good example with code to illustrate the use of <code>pytest-cov</code>.</p> <p>We can run <code>python -m coverage run -m pytest .\\tests\\01_inspect\\ -vs</code> to run tests on a particular folder. This produces a <code>.coverage</code> in the root of the folder.</p> <p>To create a report in the console, we can use <code>python -m coverage report -m</code> or <code>coverage report -m</code>.</p> <p>To create an html report in <code>htmlcov</code> folder, we can use <code>python -m coverage html</code> and the report is <code>index.html</code></p> <p>We can omit tests using a <code>.coveragerc</code> file:</p> <pre><code>[run]\nomit = \n    */tests/00_check_set_up/*\n    ...\n</code></pre> <p>Some command line options:</p> <pre><code>--cov=src: Tells pytest-cov to measure coverage for the src folder.\n--cov-report=term and --cov-report=html: Generate terminal and HTML coverage reports.\n--cov-branch: Measures branch coverage as well as line coverage.\n--cov-config=none: Specifies that no external config file will be read, but coverage will still run.\n--cov-omit=src/legacy/*,src/migrations/*: Specifies the directories you want to omit from the coverage report.\n</code></pre> <p>https://pytest-with-eric.com/coverage/python-coverage-omit-subfolder/ for more ways and deeper information.</p>"},{"location":"workshop/pytest_102/#pytest-random","title":"pytest-random","text":"<p>Ideally, all tests are independent of each other and randomising the order should not change the results of the test.</p> <p>Randomising tests are a good way to test this.</p>"},{"location":"workshop/pytest_102/#pytest-xdist","title":"pytest-xdist","text":"<p>Using <code>python -m pytest -vs .\\tests\\00_check_setup\\Xtest_09_xdist.py</code> with there being 4 tests in this test file, the overhead to set up 4 workers is around 2 seconds.</p> <p>The file has X at beginning to avoid being called when we do a general pytest run as this would slow things down.</p> <p>This does show how we can call any file for a test run. We just need <code>test_</code> etc if we want PyTest to discover the tests.</p> <p></p> <p>Running with n=1, the test took around 21s. Running with n=4, the test took around 8s. Running with n=8, the test took around 9s as there is overhead with managing workers.</p> <p>There are plugins wich can split tests based on execution time based on previous runs, (which we have in our results.csv file).</p> <p> </p>"},{"location":"workshop/welcome/","title":"Welcome","text":"<p>Let's get comfortable and confident with PyTest.</p> <p>Welcome to the Getting Started with PyTest workshop.</p> <p>There are a lot of resources both for the workshop and after so that you can feel comfortable and confident with PyTest.</p> <p>There are a lot of features to PyTest and 80% of usage uses just 20% so I will highlight the essentials, the rest you just need to be aware of rather than fully grasp now.</p>"},{"location":"workshop/welcome/#who_am_i","title":"Who am I?","text":"<p>I am an 'adhoc' freelance Backend Pythonista and Test Automation Engineer living in Brighton, UK. </p>"},{"location":"workshop/welcome/#volounteer_coach","title":"Volounteer coach","text":"<p>I am a volounteer coach at codebar.io/brighton and I also enjoy working in community kitchens, dog walking and partner dancing.</p> <p></p>"},{"location":"workshop/welcome/#my_first_computer_1979","title":"My first computer 1979","text":"<p> https://en.wikipedia.org/wiki/Punched_tape#/media/File:Creed_model_6S-2_paper_tape_reader.jpg</p>"},{"location":"workshop/welcome/#motivation","title":"Motivation","text":"<p>There are many great resources for PyTest and I wanted to curate them into one resource.</p> <p>In my experience, I look for 3 things;</p> <ol> <li>Good docs.</li> <li>A repo that works out of the box.</li> <li>Videos to explain concepts.</li> </ol> <p>I hope PyTest FullStack, (PFS), achieves this.</p> <p>We will work in a circular way, going back to concepts we have seen before. This helps learning, so don't be too concerned if things don't click at first.</p>"},{"location":"workshop/welcome/#agenda","title":"Agenda","text":"<p>We will split the workshop into four main sections:</p>"},{"location":"workshop/welcome/#1_pfs_framework","title":"1. PFS framework","text":"<p>Having seen a demo of a minimal installation of PyTest, we will get familiar with all the resources available and download Python Full Stack which is a complete framework for PyTest with over 200 template tests from SQL to API/E2E testing with Playwright. </p> <p>Learn how to create this framework from scratch and we will learn how to use it and run/select tests.</p> <p>Please note you can just install PyTest and add a <code>tests</code> folder to your project and this will work fine.</p>"},{"location":"workshop/welcome/#2_pytest_101","title":"2. PyTest 101","text":"<ul> <li>Create functional and class based test templates.</li> <li>Test discovery customisation.</li> <li>Running tests.</li> <li>Selecting tests with <code>-k</code> (like) and markers.</li> <li>Using built in markers to skip tests etc.</li> </ul>"},{"location":"workshop/welcome/#3_pytest_102","title":"3. PyTest 102","text":"<p>We will look at PyTest features to make testing easier:</p> <ul> <li>Fixtures</li> <li>Parametrization</li> <li>Conftest.py</li> <li>Plugins for HTML Reports, Coverage and performance, (pytest-xdist).</li> </ul>"},{"location":"workshop/welcome/#4_afterwards","title":"4. Afterwards","text":"<p>We will look at a great many resources available afterwards to help refresh and deepen your understanding. These range from videos, some made by me and the rest by the community, as well articles and other materials.</p> <p>https://pytest-cookbook.com/learn/.</p> <p>My intention is for you to feel comfortable and confident with PyTest, ready to use and deepen your skill set from today.</p> <p></p>"}]}